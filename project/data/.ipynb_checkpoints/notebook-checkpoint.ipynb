{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Once deleted, variables cannot be recovered. Proceed (y/[n])? y\n"
     ]
    }
   ],
   "source": [
    "# [CLEAR VARIABLES]\n",
    "%reset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------------------------------------------------------------------------------------------- \n",
      "Data set: 378661 samples\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Null values:\n",
      "ID                     0\n",
      "name                   4\n",
      "category               0\n",
      "main_category          0\n",
      "currency               0\n",
      "deadline               0\n",
      "goal                   0\n",
      "launched               0\n",
      "pledged                0\n",
      "state                  0\n",
      "backers                0\n",
      "country                0\n",
      "usd pledged         3797\n",
      "usd_pledged_real       0\n",
      "usd_goal_real          0\n",
      "dtype: int64\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Percentage missing for \"name\" 0.0011%\n",
      "Percentage missing for \"usd pledged\" 1.0027%\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Outcomes:  ['failed', 'canceled', 'successful', 'live', 'undefined', 'suspended']\n",
      "----------------------------------------------------------------------------------------------------\n",
      "The amount of live projects is:  2799\n",
      "This is 0.74% of the total projects\n",
      "----------------------------------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "# RESOURCES\n",
    "# https://towardsdatascience.com/train-test-split-and-cross-validation-in-python-80b61beca4b6\n",
    "# https://www.youtube.com/watch?v=R-sQT9AB5cI&ab_channel=AIQCAR\n",
    "# https://www.dataquest.io/blog/learning-curves-machine-learning/\n",
    "\n",
    "# TODO: create feature that shows within a category, how much mony was spent in the last week/month\n",
    "# TODO: create feature that shows ratio of successful/failed projects in the last month\n",
    "\n",
    "# [IMPORT PACKAGES]\n",
    "import sys\n",
    "import pandas as pd\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import IPython as ip\n",
    "from IPython import display as display\n",
    "import seaborn as sns\n",
    "import sklearn as sk\n",
    "import random\n",
    "import time\n",
    "\n",
    "# [IMPORT DATA]\n",
    "ks = pd.read_csv('ks2018.csv')\n",
    "print(\"-\"*100,'\\nData set: {} samples'.format(ks.shape[0]))\n",
    "print(\"-\"*100)\n",
    "\n",
    "# [NULL DATA]\n",
    "print('Null values:')\n",
    "print(ks.isnull().sum())\n",
    "print(\"-\"*100)\n",
    "print('Percentage missing for \"name\" %.4f%%' %((ks['name'].isnull().sum()/ks.shape[0])*100))\n",
    "print('Percentage missing for \"usd pledged\" %.4f%%' %((ks['usd pledged'].isnull().sum()/ks.shape[0])*100))\n",
    "print(\"-\"*100)\n",
    "\n",
    "# [ANALYZE POSSIBLE OUTCOMES]\n",
    "print('Outcomes: ', list(ks.state.unique()))\n",
    "print(\"-\"*100)\n",
    "\n",
    "# [LIVE PROJECTS]\n",
    "live = ks.apply(lambda x: True if x['state'] == 'live' else False , axis=1)\n",
    "print('The amount of live projects is: ', len(live[live == True].index))\n",
    "print('This is %.2f%% of the total projects' %((len(live[live == True].index)/ks.shape[0])*100))\n",
    "print(\"-\"*100)\n",
    "\n",
    "pd.set_option('display.max_columns', None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------------------------------------------------------------------------------------------- \n",
      "New data set: 1000 samples\n",
      "----------------------------------------------------------------------------------------------------\n",
      "                ID                                               name  \\\n",
      "226101    21931240              I-G-G-Y does C-H-I-L-L-I in Bollywood   \n",
      "316979   684628357  Fair-trade handmade jewellery created for the ...   \n",
      "157917  1803302315                                  Matinee Eclectica   \n",
      "3248    1016770882                    Coffin Syrup - Enamel Pin Badge   \n",
      "274476   466787366                     ALDancers May 2014 Poland Tour   \n",
      "\n",
      "           category main_category currency   deadline    goal  \\\n",
      "226101       Comedy  Film & Video      AUD 2014-10-24   500.0   \n",
      "316979      Jewelry       Fashion      GBP 2016-11-16  5000.0   \n",
      "157917       Comics        Comics      USD 2011-04-04  2500.0   \n",
      "3248    Accessories       Fashion      SEK 2017-12-21  5380.0   \n",
      "274476        Dance         Dance      USD 2014-05-12  3000.0   \n",
      "\n",
      "                  launched  pledged       state  backers country  usd pledged  \\\n",
      "226101 2014-09-24 06:40:35    165.0      failed        5      AU       146.58   \n",
      "316979 2016-10-17 18:23:52     35.0      failed        2      GB        24.38   \n",
      "157917 2011-01-26 03:30:06   3135.0  successful       59      US      3135.00   \n",
      "3248   2017-11-21 18:25:12   7290.0  successful       57      SE       257.70   \n",
      "274476 2014-04-16 05:55:30   3107.0  successful       37      US      3107.00   \n",
      "\n",
      "        usd_pledged_real  usd_goal_real  outcome  \n",
      "226101            145.09         439.68      0.0  \n",
      "316979             43.15        6164.01      0.0  \n",
      "157917           3135.00        2500.00      1.0  \n",
      "3248              869.94         642.01      1.0  \n",
      "274476           3107.00        3000.00      1.0  \n"
     ]
    }
   ],
   "source": [
    "# DATA [CORRECTION, COMPLETION, CONVERSION, DELETION]\n",
    "\n",
    "# remove live projects (0.74% of all data)\n",
    "ks = ks.query('state != \"live\"')\n",
    "\n",
    "# set state to 1 if successful, 0 otherwise, 1 is used for the 'rare class', there are more failed projects thant successful projects\n",
    "ks['outcome'] = (ks['state'] == 'successful').astype(float)\n",
    "\n",
    "# remove projects with null names (0.0011% of all data)\n",
    "ks.drop(ks[ks.name.isnull()].index, axis=0, inplace=True, errors='ignore')\n",
    "\n",
    "# remove outliers: goal over 30 000 000 (unrealistic, jokes)\n",
    "ks.drop(ks[ks.goal > 30000000].index, inplace=True, errors='ignore')\n",
    "\n",
    "# convert launched and deadline columns to datetime objects\n",
    "ks['launched'] = pd.to_datetime(ks['launched'])\n",
    "ks['deadline'] = pd.to_datetime(ks['deadline'])\n",
    "\n",
    "# give unix-time anomalies a new launch date, 30 days before deadline (median, in order to not mess with data)\n",
    "ks.loc[pd.DatetimeIndex(ks['launched']).year < 2000, 'launched'] = ks['deadline'] - pd.to_timedelta(30, unit='d')\n",
    "\n",
    "# reduce size of dataset\n",
    "ks = ks.sample(1000) \n",
    "\n",
    "print(\"-\"*100,'\\nNew data set: {} samples'.format(ks.shape[0]))\n",
    "print(\"-\"*100)\n",
    "\n",
    "print(ks.head(5))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                       outcome\n",
      "ID                    0.032833\n",
      "goal                  0.215923\n",
      "pledged               0.097018\n",
      "backers               0.236952\n",
      "usd pledged           0.307198\n",
      "usd_pledged_real      0.251325\n",
      "usd_goal_real         0.068601\n",
      "outcome               1.000000\n",
      "tlength               0.115092\n",
      "duration              0.155565\n",
      "lyear                 0.100510\n",
      "lmonth                0.053666\n",
      "lday                  0.022680\n",
      "lhour                 0.024404\n",
      "l_is_weekend          0.019835\n",
      "dyear                 0.101888\n",
      "dmonth                0.070167\n",
      "dday                  0.084277\n",
      "project_competition   0.055170\n",
      "category_competition  0.021655\n",
      "success_ratio         0.125125\n",
      "money_spent           0.005347\n",
      "             ID                                             name  category  \\\n",
      "0      21931240            I-G-G-Y does C-H-I-L-L-I in Bollywood        20   \n",
      "1     815251646                                    High Patrol 2        20   \n",
      "2    2122208550         Waiting In The Wings: The Musical Sequel        20   \n",
      "3    2042238786                                  A Slight Hiccup        20   \n",
      "4     549646200  Tuna: A Grindr's Tale/ Not Your Average Hook-up        20   \n",
      "..          ...                                              ...       ...   \n",
      "989  1611864053        Lake District Landscape Photographic Book        85   \n",
      "990    84063772             NATTEN – photobook by Margot Wallard        85   \n",
      "991  1727329894              PHOTOTHERAPY FOR VETERAN (Canceled)        87   \n",
      "992   268024277                       It’s time I got a new job.        87   \n",
      "993   688328065  100 Miles OF Wilderness for my Deceased Brother        80   \n",
      "\n",
      "     main_category currency   deadline       goal            launched  \\\n",
      "0                6      AUD 2014-10-24   6.214608 2014-09-24 06:40:35   \n",
      "1                6      USD 2016-07-01   6.802395 2016-05-02 16:50:05   \n",
      "2                6      USD 2016-02-21   9.903488 2016-01-21 05:20:47   \n",
      "3                6      USD 2015-01-07   8.006368 2014-12-08 20:07:33   \n",
      "4                6      USD 2017-09-14   8.006368 2017-08-15 18:09:21   \n",
      "..             ...      ...        ...        ...                 ...   \n",
      "989             11      GBP 2014-08-28   8.006368 2014-07-29 18:13:25   \n",
      "990             11      SEK 2017-04-08  11.695247 2017-03-09 13:29:06   \n",
      "991             11      USD 2014-09-08   6.907755 2014-08-09 18:41:50   \n",
      "992             11      EUR 2016-05-26   9.645364 2016-04-26 22:03:53   \n",
      "993             11      USD 2016-06-20   9.615805 2016-05-27 22:24:10   \n",
      "\n",
      "     pledged       state  backers country  usd pledged  usd_pledged_real  \\\n",
      "0      165.0      failed        5      AU       146.58            145.09   \n",
      "1        0.0      failed        0      US         0.00              0.00   \n",
      "2    21435.0  successful       70      US     21435.00          21435.00   \n",
      "3      185.0      failed        6      US       185.00            185.00   \n",
      "4     3000.0  successful       17      US      1355.00           3000.00   \n",
      "..       ...         ...      ...     ...          ...               ...   \n",
      "989    205.0      failed        4      GB       348.03            339.94   \n",
      "990  26540.0    canceled       35      SE       554.50           2944.28   \n",
      "991      0.0    canceled        0      US         0.00              0.00   \n",
      "992     25.0      failed        1      DE        28.11             27.92   \n",
      "993      0.0      failed        0      US         0.00              0.00   \n",
      "\n",
      "     usd_goal_real  outcome  tlength  duration category_country  lyear  \\\n",
      "0           439.68      0.0       37        30        Comedy_AU   2014   \n",
      "1           900.00      0.0       13        59        Comedy_US   2016   \n",
      "2         20000.00      1.0       40        31        Comedy_US   2016   \n",
      "3          3000.00      0.0       15        29        Comedy_US   2014   \n",
      "4          3000.00      1.0       47        29        Comedy_US   2017   \n",
      "..             ...      ...      ...       ...              ...    ...   \n",
      "989        4974.71      0.0       41        29    Photobooks_GB   2014   \n",
      "990       13312.48      0.0       36        29    Photobooks_SE   2017   \n",
      "991        1000.00      0.0       35        29        Places_US   2014   \n",
      "992       17254.47      0.0       26        29        Places_DE   2016   \n",
      "993       15000.00      0.0       47        23        People_US   2016   \n",
      "\n",
      "     lmonth  lday  lhour  l_is_weekend  dyear  dmonth  dday  \\\n",
      "0         9     2      6             0   2014      10     4   \n",
      "1         5     0     16             0   2016       7     4   \n",
      "2         1     3      5             0   2016       2     6   \n",
      "3        12     0     20             0   2015       1     2   \n",
      "4         8     1     18             0   2017       9     3   \n",
      "..      ...   ...    ...           ...    ...     ...   ...   \n",
      "989       7     1     18             0   2014       8     3   \n",
      "990       3     3     13             0   2017       4     5   \n",
      "991       8     5     18             1   2014       9     0   \n",
      "992       4     1     22             0   2016       5     3   \n",
      "993       5     4     22             0   2016       6     0   \n",
      "\n",
      "     project_competition  category_competition  success_ratio  money_spent  \\\n",
      "0                    4.0           1743.452917       0.300000     77517.00   \n",
      "1                    4.0           2459.488333       0.366667    219920.79   \n",
      "2                    3.0           1044.208611       0.400000    459504.25   \n",
      "3                    1.0           1813.449444       0.200000     99461.79   \n",
      "4                    5.0           3249.793056       0.366667   5214042.72   \n",
      "..                   ...                   ...            ...          ...   \n",
      "989                  5.0           1743.452917       0.200000     67795.67   \n",
      "990                  3.0          22891.261389       0.266667    130463.00   \n",
      "991                  2.0           1743.452917       0.200000     70803.62   \n",
      "992                  1.0          15027.367500       0.433333    299565.61   \n",
      "993                  4.0           1743.452917       0.333333    221479.79   \n",
      "\n",
      "     Art  Comics  Crafts  Dance  Design  Fashion  Film & Video  Food  Games  \\\n",
      "0      0       0       0      0       0        0             1     0      0   \n",
      "1      0       0       0      0       0        0             1     0      0   \n",
      "2      0       0       0      0       0        0             1     0      0   \n",
      "3      0       0       0      0       0        0             1     0      0   \n",
      "4      0       0       0      0       0        0             1     0      0   \n",
      "..   ...     ...     ...    ...     ...      ...           ...   ...    ...   \n",
      "989    0       0       0      0       0        0             0     0      0   \n",
      "990    0       0       0      0       0        0             0     0      0   \n",
      "991    0       0       0      0       0        0             0     0      0   \n",
      "992    0       0       0      0       0        0             0     0      0   \n",
      "993    0       0       0      0       0        0             0     0      0   \n",
      "\n",
      "     Journalism  Music  Photography  Publishing  Technology  Theater  \\\n",
      "0             0      0            0           0           0        0   \n",
      "1             0      0            0           0           0        0   \n",
      "2             0      0            0           0           0        0   \n",
      "3             0      0            0           0           0        0   \n",
      "4             0      0            0           0           0        0   \n",
      "..          ...    ...          ...         ...         ...      ...   \n",
      "989           0      0            1           0           0        0   \n",
      "990           0      0            1           0           0        0   \n",
      "991           0      0            1           0           0        0   \n",
      "992           0      0            1           0           0        0   \n",
      "993           0      0            1           0           0        0   \n",
      "\n",
      "     mean_category_goal  category_count  mean_main_category_goal  \\\n",
      "0              9.052772              48                 8.982747   \n",
      "1              9.052772              48                 8.982747   \n",
      "2              9.052772              48                 8.982747   \n",
      "3              9.052772              48                 8.982747   \n",
      "4              9.052772              48                 8.982747   \n",
      "..                  ...             ...                      ...   \n",
      "989            9.850807              22                 8.490018   \n",
      "990            9.850807              22                 8.490018   \n",
      "991            8.276560              22                 8.490018   \n",
      "992            8.276560              22                 8.490018   \n",
      "993            9.615805              11                 8.490018   \n",
      "\n",
      "     main_category_count  diff_mean_category_goal  \n",
      "0                   9971                 2.768139  \n",
      "1                   9971                 2.180352  \n",
      "2                   9971                -0.920740  \n",
      "3                   9971                 0.976380  \n",
      "4                   9971                 0.976380  \n",
      "..                   ...                      ...  \n",
      "989                 2533                 0.483650  \n",
      "990                 2533                -3.205229  \n",
      "991                 2533                 1.582263  \n",
      "992                 2533                -1.155346  \n",
      "993                 2533                -1.125788  \n",
      "\n",
      "[994 rows x 51 columns]\n"
     ]
    }
   ],
   "source": [
    "# FEATURE [CREATION, ENGINEERING]\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "# log transformation on goal column\n",
    "ks['goal'] = np.log(ks.goal)\n",
    "\n",
    "# create titlelength feature (length of the project name)\n",
    "ks['tlength'] = ks['name'].str.len()\n",
    "\n",
    "# create duration feature (campaign duration in days, rounded up)\n",
    "ks['duration'] = ((ks['deadline'] - ks['launched']) / np.timedelta64(1, 'D')).round(0).astype(int)\n",
    "\n",
    "# remove outliers: duration over 85\n",
    "ks.drop(ks[ks.duration > 85].index, inplace=True, errors='ignore')\n",
    "\n",
    "# create category_country feature (combination of category + country)\n",
    "ks['category_country'] = ks['category'] + \"_\" + ks['country']\n",
    "\n",
    "# create launch features (year, month [1,12], day of week [0,6], hour and is_weekend)\n",
    "ks['lyear'] = pd.DatetimeIndex(ks['launched']).year\n",
    "ks['lmonth'] = pd.DatetimeIndex(ks['launched']).month\n",
    "ks['lday'] = pd.DatetimeIndex(ks['launched']).dayofweek\n",
    "ks['lhour'] = pd.DatetimeIndex(ks['launched']).hour\n",
    "ks[\"l_is_weekend\"] = ks[\"lday\"].apply(lambda x: 1 if x > 4 else 0)\n",
    "\n",
    "# create deadline features (year, month [1,12] and day of week [0,6])\n",
    "ks['dyear'] = pd.DatetimeIndex(ks['deadline']).year\n",
    "ks['dmonth'] = pd.DatetimeIndex(ks['deadline']).month\n",
    "ks['dday'] = pd.DatetimeIndex(ks['deadline']).dayofweek \n",
    "\n",
    "# create project_competition feature (number of projects launched in past week)\n",
    "launches = pd.Series(ks.index, index=ks.launched, name=\"project_competition\").sort_index()\n",
    "project_competition = launches.rolling('7d').count() - 1 \n",
    "project_competition.index = launches.values\n",
    "ks['project_competition'] = project_competition.reindex(ks.index)\n",
    "\n",
    "# create category_competition feature (time since last project in same category was launched)\n",
    "def time_since_last_project(series): return series.diff().dt.total_seconds() / 3600.\n",
    "df = ks[['category', 'launched']].sort_values('launched')\n",
    "timedeltas = df.groupby('category').transform(time_since_last_project)\n",
    "ks['category_competition'] = timedeltas.fillna(timedeltas.median()).reindex(ks.index)\n",
    "\n",
    "# create success ratio feature (kickstarter success ratio during previous month)\n",
    "df = ks[['outcome', 'deadline']].sort_values('deadline')\n",
    "df['outcome'] = df['outcome'].astype(float)\n",
    "df['sum_outcomes'] = df['outcome'].rolling(window=30).sum() - df['outcome'] \n",
    "df['count_outcomes'] = df['outcome'].rolling(window=30).count()\n",
    "df['success_ratio'] = df['sum_outcomes']/df['count_outcomes']\n",
    "ks['success_ratio'] = df['success_ratio'].fillna(df['success_ratio'].median()).reindex(ks.index)\n",
    "\n",
    "# create money spent feature (how much money was already spent last month)\n",
    "df = ks[['pledged', 'deadline']].sort_values('deadline')\n",
    "df['sum_pledged'] = df['pledged'].rolling(window=30).sum() - df['pledged'] \n",
    "ks['money_spent'] = df['sum_pledged'].fillna(df['sum_pledged'].median()).reindex(ks.index)\n",
    "\n",
    "print(ks.corr().abs()[['outcome']])\n",
    "\n",
    "# transform category in multiple colums with one hot encoding, so it can be used to compute category related features\n",
    "ks = pd.concat([ks, pd.get_dummies(ks[\"main_category\"])], axis = 1)\n",
    "le = LabelEncoder()\n",
    "for c in [\"category\", \"main_category\"]:\n",
    "    ks[c] = le.fit_transform(ks[c])\n",
    "\n",
    "# create category related features\n",
    "t2 = ks.groupby(\"main_category\").agg({\"goal\" : \"mean\", \"category\" : \"sum\"})\n",
    "t1 = ks.groupby(\"category\").agg({\"goal\" : \"mean\", \"main_category\" : \"sum\"})\n",
    "t2 = t2.reset_index().rename(columns={\"goal\" : \"mean_main_category_goal\", \"category\" : \"main_category_count\"})\n",
    "t1 = t1.reset_index().rename(columns={\"goal\" : \"mean_category_goal\", \"main_category\" : \"category_count\"})\n",
    "ks = ks.merge(t1, on = \"category\")\n",
    "ks = ks.merge(t2, on = \"main_category\")\n",
    "\n",
    "ks[\"diff_mean_category_goal\"] = ks[\"mean_category_goal\"] - ks[\"goal\"]\n",
    "ks[\"diff_mean_category_goal\"] = ks[\"mean_main_category_goal\"] - ks[\"goal\"]\n",
    "\n",
    "# create money spent feature\n",
    "#def mony_spend_last_month():\n",
    "    \n",
    "#df = ks[['category', 'launched', 'deadline', 'usd pledged']].sort_values('launched')\n",
    "#moneydeltas = df.groupby('category').transform(mony_spend_last_month)\n",
    "#moneydeltas = moneydeltas.fillna(moneydeltas.median()).reindex(ks.index)\n",
    "\n",
    "#ks['category_money'] = moneydeltas\n",
    "#print(df)\n",
    "\n",
    "# print result\n",
    "print(ks)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYUAAAEGCAYAAACKB4k+AAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+WH4yJAAARFUlEQVR4nO3dfayedX3H8feHouATAcYpqy2uzFS3wsSHIz7OODGjOmc7M1ydD1WJ3QMzGmcW2D+6LU38x2WODE2DSt2crEORSja3ptORZY5yUFQKNDSicNZKq0zFh9QVv/vjvvrbTc857Q30OveB834lJ9d1/a7f7zrfQ+7yyfX0u1NVSJIEcMK4C5AkLRyGgiSpMRQkSY2hIElqDAVJUnPiuAt4JM4444xauXLluMuQpEeVm2+++TtVNTHbvkd1KKxcuZKpqalxlyFJjypJvjXXPi8fSZIaQ0GS1BgKkqTGUJAkNYaCJKkxFCRJjaEgSWoMBUlSYyhIkppH9RvNx8OHb7ph3CVoAfqD579s3CVIY+GZgiSpMRQkSY2hIElqDAVJUtNrKCQ5Nck1Se5IcnuSFyU5Pcn2JHd2y9OG+l+WZE+S3Uku7LM2SdJMfZ8pfAj4fFX9EnAecDtwKbCjqlYBO7ptkqwG1gPnAGuAK5Is6bk+SdKQ3kIhySnAy4CPAlTVT6vqe8BaYEvXbQuwrltfC1xdVQer6i5gD3B+X/VJkmbq80zhF4EDwMeTfCXJlUmeBJxZVfsAuuXSrv9y4J6h8dNdmyRpnvQZCicCzwU+XFXPAX5Ed6loDpmlrWZ0SjYmmUoydeDAgeNTqSQJ6DcUpoHpqrqx276GQUjcm2QZQLfcP9T/rKHxK4C9Rx60qjZX1WRVTU5MzPq905Kkh6m3UKiqbwP3JHlm13QBcBuwDdjQtW0AruvWtwHrk5yU5GxgFbCzr/okSTP1PffRO4FPJnk88A3gbQyCaGuSi4G7gYsAqmpXkq0MguMQcElVPdBzfZKkIb2GQlXdAkzOsuuCOfpvAjb1WZMkaW6+0SxJagwFSVJjKEiSGkNBktQYCpKkxlCQJDWGgiSpMRQkSY2hIElqDAVJUmMoSJIaQ0GS1BgKkqTGUJAkNYaCJKkxFCRJjaEgSWoMBUlSYyhIkhpDQZLUGAqSpMZQkCQ1hoIkqTEUJElNr6GQ5JtJvp7kliRTXdvpSbYnubNbnjbU/7Ike5LsTnJhn7VJkmaajzOFX6uqZ1fVZLd9KbCjqlYBO7ptkqwG1gPnAGuAK5IsmYf6JEmdcVw+Wgts6da3AOuG2q+uqoNVdRewBzh/DPVJ0qLVdygU8K9Jbk6ysWs7s6r2AXTLpV37cuCeobHTXZskaZ6c2PPxX1JVe5MsBbYnueMofTNLW83oNAiXjQBPe9rTjk+VkiSg5zOFqtrbLfcD1zK4HHRvkmUA3XJ/130aOGto+Apg7yzH3FxVk1U1OTEx0Wf5krTo9BYKSZ6U5CmH14FfB24FtgEbum4bgOu69W3A+iQnJTkbWAXs7Ks+SdJMfV4+OhO4Nsnh3/P3VfX5JDcBW5NcDNwNXARQVbuSbAVuAw4Bl1TVAz3WJ0k6Qm+hUFXfAM6bpf27wAVzjNkEbOqrJknS0flGsySpMRQkSY2hIElqDAVJUmMoSJIaQ0GS1BgKkqTGUJAkNYaCJKkxFCRJjaEgSWoMBUlSYyhIkhpDQZLUGAqSpMZQkCQ1hoIkqTEUJEmNoSBJagwFSVJjKEiSGkNBktQYCpKkxlCQJDWGgiSp6T0UkixJ8pUk13fbpyfZnuTObnnaUN/LkuxJsjvJhX3XJkl6sPk4U3gXcPvQ9qXAjqpaBezotkmyGlgPnAOsAa5IsmQe6pMkdXoNhSQrgN8ArhxqXgts6da3AOuG2q+uqoNVdRewBzi/z/okSQ/W95nCXwF/AvxsqO3MqtoH0C2Xdu3LgXuG+k13bQ+SZGOSqSRTBw4c6KdqSVqkeguFJK8B9lfVzaMOmaWtZjRUba6qyaqanJiYeEQ1SpIe7MQej/0S4LVJXg2cDJyS5O+Ae5Msq6p9SZYB+7v+08BZQ+NXAHt7rE+SdITezhSq6rKqWlFVKxncQP63qnoTsA3Y0HXbAFzXrW8D1ic5KcnZwCpgZ1/1SZJm6vNMYS4fALYmuRi4G7gIoKp2JdkK3AYcAi6pqgfGUJ8kLVrzEgpV9UXgi936d4EL5ui3Cdg0HzVJkmbyjWZJUmMoSJIaQ0GS1BgKkqTGUJAkNeN4JFXSCH7ykx3jLkEL0BOeMOvDm8fNSGcKSWZ8OmdrkyQ9uh31TCHJycATgTO67z04PD/RKcBTe65NkjTPjnX56PeAdzMIgJv5/1D4AfA3PdYlSRqDo4ZCVX0I+FCSd1bV5fNUkyRpTEa60VxVlyd5MbByeExVfaKnuiRJYzBSKCT5W+DpwC3A4UnqCjAUJOkxZNRHUieB1VU140tvJEmPHaO+vHYr8PN9FiJJGr9RzxTOAG5LshM4eLixql7bS1WSpLEYNRTe32cRkqSFYdSnj/6970IkSeM36tNH9zN42gjg8cDjgB9V1Sl9FSZJmn+jnik8ZXg7yTrg/F4qkiSNzcOaOruqPgu84jjXIkkas1EvH71uaPMEBu8t+M6CJD3GjPr00W8OrR8CvgmsPe7VSJLGatR7Cm/ruxBJ0viN+iU7K5Jcm2R/knuTfDrJir6LkyTNr1FvNH8c2MbgexWWA5/r2uaU5OQkO5N8NcmuJH/WtZ+eZHuSO7vlaUNjLkuyJ8nuJBc+vD9JkvRwjRoKE1X18ao61P1cBUwcY8xB4BVVdR7wbGBNkhcClwI7qmoVsKPbJslqYD1wDrAGuCLJkof8F0mSHrZRQ+E7Sd6UZEn38ybgu0cbUAM/7DYf1/0UgxvUW7r2LcC6bn0tcHVVHayqu4A9+C6EJM2rUUPh7cDrgW8D+4DfBo5587kLkFuA/cD2qroROLOq9gF0y6Vd9+XAPUPDp7u2I4+5MclUkqkDBw6MWL4kaRSjhsJfABuqaqKqljIIifcfa1BVPVBVzwZWAOcnOfco3TNL24x3Iapqc1VNVtXkxMSxrmBJkh6KUUPhWVX1P4c3quo+4Dmj/pKq+h7wRQb3Cu5NsgygW+7vuk0DZw0NWwHsHfV3SJIeuVFD4YQjnhI6nWO845BkIsmp3foTgFcCdzB4imlD120DcF23vg1Yn+SkJGcDq4Cdo/4hkqRHbtQ3mj8I/GeSaxhc0nk9sOkYY5YBW7oniE4AtlbV9Um+BGxNcjFwN3ARQFXtSrIVuI3BW9OXVNUDcxxbktSDUd9o/kSSKQaT4AV4XVXddowxX2OWS0xV9V3ggjnGbOLYYSNJ6smoZwp0IXDUIJAkPbo9rKmzJUmPTYaCJKkxFCRJjaEgSWoMBUlSYyhIkhpDQZLUGAqSpMZQkCQ1hoIkqTEUJEmNoSBJagwFSVJjKEiSGkNBktQYCpKkxlCQJDWGgiSpMRQkSY2hIElqDAVJUmMoSJIaQ0GS1PQWCknOSvKFJLcn2ZXkXV376Um2J7mzW542NOayJHuS7E5yYV+1SZJm1+eZwiHgj6vql4EXApckWQ1cCuyoqlXAjm6bbt964BxgDXBFkiU91idJOkJvoVBV+6rqy936/cDtwHJgLbCl67YFWNetrwWurqqDVXUXsAc4v6/6JEkzzcs9hSQrgecANwJnVtU+GAQHsLTrthy4Z2jYdNd25LE2JplKMnXgwIE+y5akRaf3UEjyZODTwLur6gdH6zpLW81oqNpcVZNVNTkxMXG8ypQk0XMoJHkcg0D4ZFV9pmu+N8mybv8yYH/XPg2cNTR8BbC3z/okSQ/W59NHAT4K3F5Vfzm0axuwoVvfAFw31L4+yUlJzgZWATv7qk+SNNOJPR77JcCbga8nuaVr+1PgA8DWJBcDdwMXAVTVriRbgdsYPLl0SVU90GN9kqQj9BYKVfUfzH6fAOCCOcZsAjb1VZMk6eh8o1mS1BgKkqTGUJAkNYaCJKkxFCRJjaEgSWoMBUlSYyhIkhpDQZLUGAqSpMZQkCQ1hoIkqTEUJEmNoSBJagwFSVJjKEiSGkNBktQYCpKkxlCQJDWGgiSpMRQkSY2hIElqDAVJUmMoSJKa3kIhyceS7E9y61Db6Um2J7mzW542tO+yJHuS7E5yYV91SZLm1ueZwlXAmiPaLgV2VNUqYEe3TZLVwHrgnG7MFUmW9FibJGkWvYVCVd0A3HdE81pgS7e+BVg31H51VR2sqruAPcD5fdUmSZrdfN9TOLOq9gF0y6Vd+3LgnqF+013bDEk2JplKMnXgwIFei5WkxWah3GjOLG01W8eq2lxVk1U1OTEx0XNZkrS4zHco3JtkGUC33N+1TwNnDfVbAeyd59okadGb71DYBmzo1jcA1w21r09yUpKzgVXAznmuTZIWvRP7OnCSTwEvB85IMg28D/gAsDXJxcDdwEUAVbUryVbgNuAQcElVPdBXbZKk2fUWClX1hjl2XTBH/03Apr7qkSQd20K50SxJWgAMBUlSYyhIkhpDQZLUGAqSpMZQkCQ1hoIkqTEUJEmNoSBJagwFSVJjKEiSGkNBktQYCpKkxlCQJDWGgiSpMRQkSY2hIElqDAVJUmMoSJIaQ0GS1BgKkqTGUJAkNYaCJKkxFCRJzYILhSRrkuxOsifJpeOuR5IWkwUVCkmWAH8DvApYDbwhyerxViVJi8eCCgXgfGBPVX2jqn4KXA2sHXNNkrRonDjuAo6wHLhnaHsaeMFwhyQbgY3d5g+T7J6n2haDM4DvjLuIheAPx12AjuRn8/j6hbl2LLRQyCxt9aCNqs3A5vkpZ3FJMlVVk+OuQzqSn835s9AuH00DZw1trwD2jqkWSVp0Floo3ASsSnJ2kscD64FtY65JkhaNBXX5qKoOJfkj4F+AJcDHqmrXmMtaTLwsp4XKz+Y8SVUdu5ckaVFYaJePJEljZChIkhpDYRE61lQiGfjrbv/Xkjx3HHVq8UnysST7k9w6x34/mz0zFBaZEacSeRWwqvvZCHx4XovUYnYVsOYo+/1s9sxQWHxGmUpkLfCJGvgv4NQky+a7UC0+VXUDcN9RuvjZ7JmhsPjMNpXI8ofRRxoHP5s9MxQWn2NOJTJiH2kc/Gz2zFBYfEaZSsTpRrRQ+dnsmaGw+Iwylcg24C3dkx4vBL5fVfvmu1BpFn42e7agprlQ/+aaSiTJ73f7PwL8E/BqYA/wY+Bt46pXi0uSTwEvB85IMg28D3gc+NmcL05zIUlqvHwkSWoMBUlSYyhIkhpDQZLUGAqSpMZQkB6iJG9N8tRx1yH1wVCQHrq3AoaCHpN8T0ECkrwHeHu3eSXwWeD6qjq32/9e4MnArQymd/5v4CfAi4BzgQ8BTwIOAhcA/8tgWudJ4BDwnqr6QpK3AusYvDh4LvBB4PHAm7uxr66q+5I8ncEU5xMMXtJ6R1Xd0d9/AWnAMwUtekmex+DN2BcALwTeAZw2W9+qugaYAt5YVc8GHgD+AXhXVZ0HvJJBWFzS9f8V4A3AliQnd4c5F/hdBtOYbwJ+XFXPAb4EvKXrsxl4Z1U9D3gvcMXx/JuluTjNhQQvBa6tqh8BJPkM8Ksjjn0msK+qbgKoqh90x3gpcHnXdkeSbwHP6MZ8oaruB+5P8n3gc13714FnJXky8GLgH5M2KehJj+Dvk0ZmKEizT8d8Kg8+kz55lj6Hx852DXa2Yx52cGj9Z0PbP2Pwb/IE4HvdmYg0r7x8JMENwLokT0zyJOC3gH8Glib5uSQnAa8Z6n8/8JRu/Q7gqUmeD5DkKUlO7I75xq7tGcDTgN2jFNOdbdyV5KJufJKc90j/SGkUhoIWvar6MoObxzuBG4Eru8tBf95tX8/gf/6HXQV8JMktDG4Y/w5weZKvAtsZnFVcASxJ8nUG9xzeWlXDZwjH8kbg4u6Yu5j5lalSL3z6SJLUeKYgSWoMBUlSYyhIkhpDQZLUGAqSpMZQkCQ1hoIkqfk/D19yw3cKGJoAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 2160x360 with 3 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "sns.countplot(x = 'outcome', data = ks, palette = 'Set3')\n",
    "\n",
    "\n",
    "# FIND OUTLIERS\n",
    "fig, axs = plt.subplots(ncols=3, figsize=(30,5))\n",
    "\n",
    "# goal, kickstarter maximum is 100.000\n",
    "axs[0].set_title(\"goal\")\n",
    "ks['goal'].plot(kind='hist', bins=20, color='darkseagreen', edgecolor='black', log=True, range=[-5,3], ax=axs[0])\n",
    "\n",
    "# tlength\n",
    "axs[1].set_title(\"tlength\")\n",
    "ks['tlength'].plot(kind='hist', bins=20, color='darkseagreen', edgecolor='black', log=True, range=[0,100], ax=axs[1])\n",
    "\n",
    "# duration\n",
    "axs[2].set_title(\"duration\")\n",
    "ks['duration'].plot(kind='hist', bins=20, color='darkseagreen', edgecolor='black', log=True, range=[0,100], ax=axs[2])\n",
    "\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   outcome  category  main_category      goal  duration  tlength  lyear  \\\n",
      "0      0.0        20              6  6.214608        30       37   2014   \n",
      "1      0.0        20              6  6.802395        59       13   2016   \n",
      "2      1.0        20              6  9.903488        31       40   2016   \n",
      "3      0.0        20              6  8.006368        29       15   2014   \n",
      "4      1.0        20              6  8.006368        29       47   2017   \n",
      "\n",
      "   lmonth  lday  l_is_weekend  lhour  dyear  dmonth  dday  \\\n",
      "0       9     2             0      6   2014      10     4   \n",
      "1       5     0             0     16   2016       7     4   \n",
      "2       1     3             0      5   2016       2     6   \n",
      "3      12     0             0     20   2015       1     2   \n",
      "4       8     1             0     18   2017       9     3   \n",
      "\n",
      "   category_competition  project_competition  mean_category_goal  \\\n",
      "0           1743.452917                  4.0            9.052772   \n",
      "1           2459.488333                  4.0            9.052772   \n",
      "2           1044.208611                  3.0            9.052772   \n",
      "3           1813.449444                  1.0            9.052772   \n",
      "4           3249.793056                  5.0            9.052772   \n",
      "\n",
      "   category_count  mean_main_category_goal  main_category_count  \\\n",
      "0              48                 8.982747                 9971   \n",
      "1              48                 8.982747                 9971   \n",
      "2              48                 8.982747                 9971   \n",
      "3              48                 8.982747                 9971   \n",
      "4              48                 8.982747                 9971   \n",
      "\n",
      "   diff_mean_category_goal  category_competition  currency   country  \\\n",
      "0                 2.768139           1743.452917  0.315789  0.315789   \n",
      "1                 2.180352           2459.488333  0.391534  0.395722   \n",
      "2                -0.920740           1044.208611  0.391534  0.395722   \n",
      "3                 0.976380           1813.449444  0.391534  0.395722   \n",
      "4                 0.976380           3249.793056  0.391534  0.395722   \n",
      "\n",
      "   category_country  \n",
      "0          0.369215  \n",
      "1          0.428425  \n",
      "2          0.428425  \n",
      "3          0.428425  \n",
      "4          0.428425  \n"
     ]
    }
   ],
   "source": [
    "# CATEGORICAL ENCODING (one-hot encoding, label encoding, count encoding, target encoding, catboost encoding)\n",
    "\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "import category_encoders as ce\n",
    "\n",
    "# categorical features to be encoded\n",
    "# features = ['category', 'currency', 'country', 'category_country']\n",
    "features = ['currency', 'country', 'category_country']\n",
    "\n",
    "# encoders\n",
    "l_encoder = LabelEncoder() # label encoding, encode target labels with value between 0 and n_classes-1.\n",
    "c_encoder = ce.CountEncoder() # count encoding, replaces each categorical value with the number of times it appears in the dataset\n",
    "t_encoder = ce.TargetEncoder(cols=features) # target encoding, replaces a categorical value with the average value of the target for that value of the feature\n",
    "cb_encoder = ce.CatBoostEncoder(cols=features) # catboost encoding, for each row, the target probability is calculated only from the rows before it\n",
    "\n",
    "# encoded features\n",
    "l_encoded = ks[features].apply(l_encoder.fit_transform)\n",
    "c_encoded = c_encoder.fit_transform(ks[features])\n",
    "t_encoded = t_encoder.fit_transform(ks[features], ks['outcome'])\n",
    "cb_encoded = cb_encoder.fit_transform(ks[features], ks['outcome'])\n",
    "\n",
    "# create data set, drop colums of features that are not useful\n",
    "ks.drop('currency', axis=1, inplace=True)\n",
    "ks.drop('country', axis=1, inplace=True)\n",
    "ks.drop('category_country', axis=1, inplace=True)\n",
    "ks.drop('name', axis=1, inplace=True)\n",
    "ks.drop('launched', axis=1, inplace=True)\n",
    "ks.drop('deadline', axis=1, inplace=True)\n",
    "ks.drop('usd pledged', axis=1, inplace=True)\n",
    "ks.drop('state', axis=1, inplace=True)\n",
    "#data = ks[['outcome', 'tlength', 'goal', 'duration', 'lyear', 'lmonth', 'lday', 'lhour', 'dyear', 'dmonth', 'dday', 'project_competition', 'category_competition']].join(t_encoded)\n",
    "data = ks[['outcome', 'category', 'main_category', 'goal', 'duration', 'tlength', 'lyear', 'lmonth', 'lday', 'l_is_weekend', 'lhour', 'dyear', 'dmonth', 'dday', 'category_competition', 'project_competition', 'mean_category_goal', 'category_count', 'mean_main_category_goal', 'main_category_count', 'diff_mean_category_goal', 'category_competition']].join(t_encoded)\n",
    "#data = ks.join(t_encoded)\n",
    "\n",
    "# print result\n",
    "print(data.head(5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    index                  Feature  Feature Importance\n",
      "0      23         category_country            0.293255\n",
      "1      19  diff_mean_category_goal            0.072607\n",
      "2       3                 duration            0.066788\n",
      "3       2                     goal            0.059212\n",
      "4      11                   dmonth            0.055273\n",
      "5       9                    lhour            0.053510\n",
      "6      12                     dday            0.045039\n",
      "7      13     category_competition            0.040973\n",
      "8       4                  tlength            0.040377\n",
      "9       6                   lmonth            0.037342\n",
      "10     22                  country            0.035906\n",
      "11     16           category_count            0.032685\n",
      "12      7                     lday            0.028233\n",
      "13     20     category_competition            0.026156\n",
      "14     15       mean_category_goal            0.025588\n",
      "15      0                 category            0.022811\n",
      "16     10                    dyear            0.019340\n",
      "17     14      project_competition            0.018395\n",
      "18      1            main_category            0.011500\n",
      "19      5                    lyear            0.010286\n",
      "20     21                 currency            0.004723\n",
      "21      8             l_is_weekend            0.000000\n",
      "22     17  mean_main_category_goal            0.000000\n",
      "23     18      main_category_count            0.000000\n"
     ]
    }
   ],
   "source": [
    "# FEATURE SELECTION\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "X = data.drop('outcome', axis = 1).values\n",
    "y = data['outcome']\n",
    "dt = DecisionTreeClassifier(random_state=15, criterion = 'entropy', max_depth = 10)\n",
    "dt.fit(X,y)\n",
    "fi_col = []\n",
    "fi = []\n",
    "for i,column in enumerate(data.drop('outcome', axis = 1)):\n",
    "    fi_col.append(column)\n",
    "    fi.append(dt.feature_importances_[i])\n",
    "fi_col\n",
    "fi\n",
    "fi_df = zip(fi_col, fi)\n",
    "fi_df = pd.DataFrame(fi_df, columns = ['Feature','Feature Importance'])\n",
    "fi_df = fi_df.sort_values('Feature Importance', ascending = False).reset_index()\n",
    "\n",
    "# Creating columns to keep\n",
    "columns_to_keep = fi_df['Feature'][0:10]\n",
    "\n",
    "print(fi_df)\n",
    "\n",
    "# feature selection\n",
    "#data = data[['outcome', 'category', 'main_category', 'category_country', 'goal', 'duration', 'tlength', 'lyear', 'lmonth', 'lday', 'l_is_weekend', 'lhour', 'dyear', 'dmonth', 'dday', 'category_competition', 'project_competition', 'mean_category_goal', 'category_count', 'mean_main_category_goal', 'main_category_count', 'diff_mean_category_goal', 'category_competition']]\n",
    "\n",
    "# correlations\n",
    "#data.corr().abs()[['outcome']]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------\n",
      "[60%] x_train:\t 596\n",
      "[20%] x_test:\t 398\n",
      "-----------------------------------\n"
     ]
    }
   ],
   "source": [
    "# SCALE AND SPLIT DATA\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "# get predictors: goal, duration, project_competition, category, category_country\n",
    "x_unscaled = data[['goal', 'duration', 'project_competition', 'category', 'category_country']]\n",
    "\n",
    "# get outcome\n",
    "y = data['outcome']\n",
    "\n",
    "# feature scaling/normalizing\n",
    "scaler = StandardScaler()\n",
    "x = pd.DataFrame(scaler.fit_transform(x_unscaled), columns=list(x_unscaled.columns))\n",
    "\n",
    "\n",
    "# split data into training, testing and validation set (60%, 20%, 20%)\n",
    "# data -> training + testing\n",
    "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.4, random_state=42)\n",
    "\n",
    "# training -> training + cross validation\n",
    "#x_train, x_valid, y_train, y_valid = train_test_split(x_train, y_train, test_size=0.25, random_state=42)\n",
    "\n",
    "print(\"-\"*35)\n",
    "print(\"[60%] x_train:\\t\", x_train.shape[0])\n",
    "#print(\"[20%] x_valid:\\t\", x_valid.shape[0])\n",
    "print(\"[20%] x_test:\\t\", x_test.shape[0])\n",
    "print(\"-\"*35)\n",
    "\n",
    "# check if data is nicely spread\n",
    "# https://imgur.com/a/cCCjKhj\n",
    "# in the image above you see that the projects with outcome 1 are evenly spread among the sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.726 (0.040)\n",
      "------------------------------------------------------------\n",
      "Logistic Regression Model Scores\n",
      "[TEST]\t 71.61%\n",
      "------------------------------------------------------------\n",
      "Classification Report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.73      0.85      0.79       244\n",
      "         1.0       0.68      0.51      0.58       154\n",
      "\n",
      "    accuracy                           0.72       398\n",
      "   macro avg       0.70      0.68      0.68       398\n",
      "weighted avg       0.71      0.72      0.71       398\n",
      "\n",
      "------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "# LOGISTIC REGRESSION \n",
    "from numpy import mean, std\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import cross_val_score, cross_val_predict\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.model_selection import learning_curve, KFold\n",
    "from sklearn import metrics\n",
    "\n",
    "# prepare the cross-validation procedure\n",
    "cv = KFold(n_splits=10, random_state=1, shuffle=True)\n",
    "\n",
    "# create model\n",
    "model = LogisticRegression()\n",
    "\n",
    "# evaluate model\n",
    "scores = cross_val_score(model, x_train, y_train, scoring='accuracy', cv=cv, n_jobs=-1)\n",
    "\n",
    "# report performance\n",
    "print('Accuracy: %.3f (%.3f)' % (mean(scores), std(scores)))\n",
    "\n",
    "\n",
    "# create model\n",
    "#model = LogisticRegression(C=0.01)\n",
    "\n",
    "# fit model on training data set\n",
    "model.fit(x_train, y_train)\n",
    "\n",
    "# test model on cross validation data set\n",
    "#y_pred_valid = model.predict(x_valid) \n",
    "\n",
    "\n",
    "# model score: score(test samples, true labels for x)\n",
    "print(\"-\"*60)\n",
    "print(\"Logistic Regression Model Scores\")\n",
    "#print('[TRAIN]\\t %.2f%%' %(round(model.score(x_train, y_train),5)*100))\n",
    "#print('[VALID]\\t %.2f%%' %(round(model.score(x_valid, y_valid),5)*100))\n",
    "print('[TEST]\\t %.2f%%' %(round(model.score(x_test, y_test),5)*100))\n",
    "y_pred_test = model.predict(x_test) \n",
    "print(\"-\"*60)\n",
    "\n",
    "# classification report: classification_report(y_true, y_pred)\n",
    "print(\"Classification Report\")\n",
    "print(classification_report(y_test, y_pred_test))\n",
    "print(\"-\"*60)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'y_valid' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-10-d8c9241e99c2>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     26\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m \u001b[0;31m# confusion matrix: confusion_matrix(y_true, y_pred)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 28\u001b[0;31m \u001b[0mcnf_matrix\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmetrics\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconfusion_matrix\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_valid\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_pred_valid\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     29\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_printoptions\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprecision\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     30\u001b[0m \u001b[0mclass_names\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m'Successful'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'Failed'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'y_valid' is not defined"
     ]
    }
   ],
   "source": [
    "# CONFUSION MATRIX LOGISTIC REGRESSION\n",
    "import itertools\n",
    "\n",
    "def plot_confusion_matrix(cm, classes, normalize=False, title=\"Confusion Matrix\", cmap=plt.cm.YlGnBu):\n",
    "    if normalize: cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
    "\n",
    "    plt.imshow(cm, interpolation='nearest', cmap=cmap)\n",
    "    plt.title(title)\n",
    "    plt.colorbar()\n",
    "    tick_marks = np.arange(len(classes))\n",
    "    plt.xticks(tick_marks, classes, rotation=45)\n",
    "    plt.yticks(tick_marks, classes)\n",
    "\n",
    "    fmt = '.2f' if normalize else 'd'\n",
    "    thresh = cm.max() / 2.\n",
    "    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n",
    "        plt.text(j, i, format(cm[i, j], fmt),\n",
    "            horizontalalignment=\"center\",\n",
    "            color=\"white\" if cm[i, j] > thresh else \"black\",\n",
    "            size=\"20\")\n",
    "           \n",
    "    plt.tight_layout()\n",
    "    plt.ylabel('True label')\n",
    "    plt.xlabel('Predicted label')\n",
    "\n",
    "\n",
    "# confusion matrix: confusion_matrix(y_true, y_pred)\n",
    "cnf_matrix = metrics.confusion_matrix(y_valid, y_pred_valid)\n",
    "np.set_printoptions(precision=2)\n",
    "class_names = ['Successful', 'Failed']\n",
    "\n",
    "plt.figure()\n",
    "plot_confusion_matrix(cnf_matrix, classes=class_names, title='Confusion Matrix')\n",
    "\n",
    "plt.figure()\n",
    "plot_confusion_matrix(cnf_matrix, classes=class_names, normalize=True, title='Normalized Confusion Matrix')\n",
    "\n",
    "# evaluation of confusion matrix\n",
    "print(\"-\"*60)\n",
    "print('[ACCURACY]\\t %.2f%%' %(metrics.accuracy_score(y_valid, y_pred_valid)*100))\n",
    "print('[PRECISION]\\t %.2f%%' %(metrics.precision_score(y_valid, y_pred_valid)*100))\n",
    "print('[RECALL]\\t %.2f%%' %(metrics.recall_score(y_valid, y_pred_valid)*100))\n",
    "print(\"-\"*60)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_proba_train = model.predict_proba(x_train) # training\n",
    "y_pred_proba_test = model.predict_proba(x_test) # testing\n",
    "y_pred_proba_valid = model.predict_proba(x_valid) # validation\n",
    "\n",
    "# Running Log loss on training\n",
    "print(\"The Log Loss on Training is: \", metrics.log_loss(y_train, y_pred_proba_train))\n",
    "print(\"The Log Loss on Testing Dataset is: \", metrics.log_loss(y_test, y_pred_proba_test))\n",
    "\n",
    "# RECEIVER OPERATING CHARACTERISTIC (ROC) CURVE: roc_curve(y_true, y_score)\n",
    "print(\"ROC Curve\")\n",
    "y_pred_proba = model.predict_proba(x_test)[::,1]\n",
    "fpr, tpr, _ = metrics.roc_curve(y_test, y_pred_proba)\n",
    "auc = metrics.roc_auc_score(y_test, y_pred_proba)\n",
    "plt.plot(fpr,tpr,label=\"data 1, auc=\"+str(auc))\n",
    "plt.legend(loc=4)\n",
    "plt.show()\n",
    "print(\"Test AUC score: {auc}\")\n",
    "print(\"-\"*60)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# learning curve for when using whole dataset\n",
    "# train_sizes, train_scores, validation_scores = learning_curve(estimator = LogisticRegression(), X=x_train, y=y_train, train_sizes = [500, 1000, 1100, 1200, 1300, 1400, 1500, 1600, 1700, 1800, 1900, 2000, 3000, 4000, 5000, 6000, 7000, 8000, 9000, 1000, 15000, 20000, 25000, 25000, 30000, 35000, 40000, 45000, 50000], cv = 5)\n",
    "# learning curve for when using part of dataset\n",
    "train_sizes, train_scores, validation_scores = learning_curve(estimator = LogisticRegression(), X=x_train, y=y_train, train_sizes = [0.01, 0.02, 0.05, 0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9, 1.0], cv = 5)\n",
    "\n",
    "train_scores_mean = train_scores.mean(axis = 1)\n",
    "validation_scores_mean = validation_scores.mean(axis = 1)\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.style.use('seaborn')\n",
    "plt.plot(train_sizes, train_scores_mean, label = 'Training error')\n",
    "plt.plot(train_sizes, validation_scores_mean, label = 'Validation error')\n",
    "plt.ylabel('MSE', fontsize = 14)\n",
    "plt.xlabel('Training set size', fontsize = 14)\n",
    "plt.title('Learning curves for a logistic regression model', fontsize = 18, y = 1.03)\n",
    "plt.legend()\n",
    "#plt.ylim(0.68,0.703)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Optimal C/lambda value\n",
    "from sklearn.linear_model import LogisticRegressionCV\n",
    "from sklearn.model_selection import KFold\n",
    "kf = KFold(n_splits=3, random_state=0, shuffle=True)\n",
    "\n",
    "C_List = np.geomspace(1e-5, 1e5, num=20)\n",
    "\n",
    "# Logistic Reg CV\n",
    "Log_reg3 = LogisticRegressionCV(random_state=15, Cs = C_List, solver ='lbfgs')\n",
    "Log_reg3.fit(x_train, y_train)\n",
    "print(\"The CA is:\", Log_reg3.score(x_test, y_test))\n",
    "pred_proba_t = Log_reg3.predict_proba(x_test)\n",
    "log_loss3 = metrics.log_loss(y_test, pred_proba_t)\n",
    "print(\"The Logistic Loss is: \", log_loss3)\n",
    "\n",
    "print(\"The optimal C parameter is: \", Log_reg3.C_)\n",
    "\n",
    "\n",
    "#C_List = np.geomspace(1e-5, 1e5, num=20)\n",
    "CA = []\n",
    "Logarithmic_Loss = []\n",
    "\n",
    "for c in C_List:\n",
    "    log_reg2 = LogisticRegression(random_state=10, solver = 'lbfgs', C=c)\n",
    "    log_reg2.fit(x_train, y_train)\n",
    "    score = log_reg2.score(x_test, y_test)\n",
    "    CA.append(score)\n",
    "    print(\"The CA of C parameter {} is {}:\".format(c, score))\n",
    "    pred_proba_t = log_reg2.predict_proba(x_test)\n",
    "    log_loss2 = metrics.log_loss(y_test, pred_proba_t)\n",
    "    Logarithmic_Loss.append(log_loss2)\n",
    "    print(\"The Logg Loss of C parameter {} is {}:\".format(c, log_loss2))\n",
    "    print(\"\")\n",
    "    \n",
    "    y_pred = log_reg2.predict(x_train)\n",
    "    cm = metrics.confusion_matrix(y_train, y_pred)\n",
    "    #cm_norm = cm / cm.sum(axis=1).reshape(-1,1)\n",
    "    plot_confusion_matrix(cm, normalize=True, classes = model.classes_, title='Confusion matrix', cmap=plt.cm.YlGnBu)\n",
    "    plt.show()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# DON'T EXECUTE! crashte bij mij idk waarom\n",
    "# LightGBM\n",
    "# Tree-based model that typically provides the best performance, even compared to XGBoost. It's also relatively fast to train.\n",
    "\n",
    "import lightgbm as lgb\n",
    "from sklearn import metrics\n",
    "\n",
    "feature_cols = data.columns.drop('outcome')\n",
    "\n",
    "dtrain = lgb.Dataset(data[feature_cols], label=data['outcome'])\n",
    "dvalid = lgb.Dataset(data[feature_cols], label=data['outcome'])\n",
    "\n",
    "param = {'num_leaves': 64, 'objective': 'binary'}\n",
    "param['metric'] = 'auc'\n",
    "num_round = 1000\n",
    "bst = lgb.train(param, dtrain, num_round, valid_sets=[dvalid], early_stopping_rounds=10, verbose_eval=False)\n",
    "\n",
    "ypred = bst.predict(test[feature_cols])\n",
    "score = metrics.roc_auc_score(test['outcome'], ypred)\n",
    "\n",
    "# evaluation\n",
    "print(\"-\"*60)\n",
    "print('Aread Under Curve (AUC): %.2f%%' %(metrics.roc_auc_score(test['outcome'], ypred)*100))\n",
    "print(\"-\"*60)\n",
    "\n",
    "#76.06 (catboost)\n",
    "#76.83 (target)\n",
    "#76.34 (count)\n",
    "#76.33 (label)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# NAIVE BAYES ALGORITHM\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn import metrics\n",
    "\n",
    "# instantiate logistic regression model\n",
    "model = GaussianNB()\n",
    "\n",
    "# fit the model with the data\n",
    "model.fit(x_train,y_train)\n",
    "\n",
    "# make predictions\n",
    "predict_test = model.predict(x_test)\n",
    "\n",
    "# evaluation\n",
    "print(\"-\"*60)\n",
    "print('Accuracy: %.2f%%' %(metrics.accuracy_score(y_test, predict_test)*100))\n",
    "print('Precision: %.2f%%' %(metrics.precision_score(y_test, predict_test)*100))\n",
    "print('Recall: %.2f%%' %(metrics.recall_score(y_test, predict_test)*100))\n",
    "print(\"-\"*60)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# NEURAL NETWORK\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "\n",
    "model = keras.Sequential()\n",
    "\n",
    "model.add(layers.Dense(2, activation=\"relu\"))\n",
    "model.add(layers.Dense(3, activation=\"relu\"))\n",
    "model.add(layers.Dense(4))\n",
    "\n",
    "#model.compile(optimizer=\"adam\", loss='binary_crossentropy', metrics=['accuracy'])\n",
    "#model.fit(x_train, y_train, batch_size=32, epochs=50)\n",
    "\n",
    "#model.summary()\n",
    "\n",
    "#y_pred = model.predict_classes(x_test)\n",
    "#print(metrics.accuracy_score(y_test, y_pred))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.683 (0.031)\n",
      "------------------------------------------------------------\n",
      "Support Vector Machines Model Scores\n",
      "[TRAIN]\t 72.15%\n",
      "[TEST]\t 67.84%\n",
      "------------------------------------------------------------\n",
      "Classification Report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.67      0.95      0.78       244\n",
      "         1.0       0.75      0.25      0.38       154\n",
      "\n",
      "    accuracy                           0.68       398\n",
      "   macro avg       0.71      0.60      0.58       398\n",
      "weighted avg       0.70      0.68      0.63       398\n",
      "\n",
      "------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "# SUPORRT VECTOR MACHINES\n",
    "from sklearn import svm\n",
    "from sklearn import metrics\n",
    "from numpy import mean, std\n",
    "from sklearn.model_selection import cross_val_score, cross_val_predict\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.model_selection import learning_curve, KFold\n",
    "\n",
    "# Split dataset in train, validate, test sets\n",
    "# x_train, x_valid, x_test, y_train, y_valid, y_test\n",
    "\n",
    "# Create a svm Classifier\n",
    "svm_model = svm.SVC(kernel='rbf', C=1) # Linear Kernel, or radial basis, polynomial or sigmoid function?\n",
    "\n",
    "# prepare the cross-validation procedure\n",
    "cv = KFold(n_splits=5, random_state=1, shuffle=True)\n",
    "\n",
    "# evaluate model\n",
    "scores = cross_val_score(svm_model, x_train, y_train, scoring='accuracy', cv=cv, n_jobs=-1)\n",
    "\n",
    "# report performance\n",
    "print('Accuracy: %.3f (%.3f)' % (mean(scores), std(scores)))\n",
    "\n",
    "\n",
    "# Train the model using the training sets\n",
    "svm_model.fit(x_train, y_train)\n",
    "\n",
    "# model score: score(test samples, true labels for x)\n",
    "print(\"-\"*60)\n",
    "print(\"Support Vector Machines Model Scores\")\n",
    "print('[TRAIN]\\t %.2f%%' %(round(svm_model.score(x_train, y_train),5)*100))\n",
    "#print('[VALID]\\t %.2f%%' %(round(clf.score(x_valid, y_valid),5)*100))\n",
    "print('[TEST]\\t %.2f%%' %(round(svm_model.score(x_test, y_test),5)*100))\n",
    "y_pred_test_SVM = svm_model.predict(x_test) \n",
    "print(\"-\"*60)\n",
    "\n",
    "# classification report: classification_report(y_true, y_pred)\n",
    "print(\"Classification Report\")\n",
    "print(classification_report(y_test, y_pred_test_SVM))\n",
    "print(\"-\"*60)\n",
    "\n",
    "# evaluationg the model\n",
    "#print(\"Accuracy:\",metrics.accuracy_score(y_test, y_pred_valid))\n",
    "#print(\"Precision:\",metrics.precision_score(y_test, y_pred_valid))\n",
    "#print(\"Recall:\",metrics.recall_score(y_test, y_pred_valid))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CONFUSION MATRIX SVM\n",
    "\n",
    "def plot_confusion_matrix(cm, classes, normalize=False, title=\"Confusion Matrix\", cmap=plt.cm.YlGnBu):\n",
    "    if normalize: cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
    "\n",
    "    plt.imshow(cm, interpolation='nearest', cmap=cmap)\n",
    "    plt.title(title)\n",
    "    plt.colorbar()\n",
    "    tick_marks = np.arange(len(classes))\n",
    "    plt.xticks(tick_marks, classes, rotation=45)\n",
    "    plt.yticks(tick_marks, classes)\n",
    "\n",
    "    fmt = '.2f' if normalize else 'd'\n",
    "    thresh = cm.max() / 2.\n",
    "    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n",
    "        plt.text(j, i, format(cm[i, j], fmt),\n",
    "            horizontalalignment=\"center\",\n",
    "            color=\"white\" if cm[i, j] > thresh else \"black\",\n",
    "            size=\"20\")\n",
    "           \n",
    "    plt.tight_layout()\n",
    "    plt.ylabel('True label')\n",
    "    plt.xlabel('Predicted label')\n",
    "\n",
    "\n",
    "# confusion matrix: confusion_matrix(y_true, y_pred)\n",
    "cnf_matrix = metrics.confusion_matrix(y_valid, y_pred_valid)\n",
    "np.set_printoptions(precision=2)\n",
    "class_names = ['Successful', 'Failed']\n",
    "\n",
    "plt.figure()\n",
    "plot_confusion_matrix(cnf_matrix, classes=class_names, title='Confusion Matrix')\n",
    "\n",
    "plt.figure()\n",
    "plot_confusion_matrix(cnf_matrix, classes=class_names, normalize=True, title='Normalized Confusion Matrix')\n",
    "\n",
    "# evaluation of confusion matrix\n",
    "print(\"-\"*60)\n",
    "print('[ACCURACY]\\t %.2f%%' %(metrics.accuracy_score(y_valid, y_pred_valid_SVM)*100))\n",
    "print('[PRECISION]\\t %.2f%%' %(metrics.precision_score(y_valid, y_pred_valid_SVM)*100))\n",
    "print('[RECALL]\\t %.2f%%' %(metrics.recall_score(y_valid, y_pred_valid_SVM)*100))\n",
    "print(\"-\"*60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
