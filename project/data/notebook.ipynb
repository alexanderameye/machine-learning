{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Once deleted, variables cannot be recovered. Proceed (y/[n])? y\n"
     ]
    }
   ],
   "source": [
    "# [CLEAR VARIABLES]\n",
    "%reset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------------------------------------------------------------------------------------------- \n",
      "Data set: 378661 samples\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Null values:\n",
      "ID                     0\n",
      "name                   4\n",
      "category               0\n",
      "main_category          0\n",
      "currency               0\n",
      "deadline               0\n",
      "goal                   0\n",
      "launched               0\n",
      "pledged                0\n",
      "state                  0\n",
      "backers                0\n",
      "country                0\n",
      "usd pledged         3797\n",
      "usd_pledged_real       0\n",
      "usd_goal_real          0\n",
      "dtype: int64\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Percentage missing for \"name\" 0.0011%\n",
      "Percentage missing for \"usd pledged\" 1.0027%\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Outcomes:  ['failed', 'canceled', 'successful', 'live', 'undefined', 'suspended']\n",
      "----------------------------------------------------------------------------------------------------\n",
      "The amount of live projects is:  2799\n",
      "This is 0.74% of the total projects\n",
      "----------------------------------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "# RESOURCES\n",
    "# https://towardsdatascience.com/train-test-split-and-cross-validation-in-python-80b61beca4b6\n",
    "# https://www.youtube.com/watch?v=R-sQT9AB5cI&ab_channel=AIQCAR\n",
    "# https://www.dataquest.io/blog/learning-curves-machine-learning/\n",
    "\n",
    "# TODO: create feature that shows within a category, how much mony was spent in the last week/month\n",
    "# TODO: create feature that shows ratio of successful/failed projects in the last month\n",
    "\n",
    "# [IMPORT PACKAGES]\n",
    "import sys\n",
    "import pandas as pd\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import IPython as ip\n",
    "from IPython import display as display\n",
    "import seaborn as sns\n",
    "import sklearn as sk\n",
    "import random\n",
    "import time\n",
    "\n",
    "# [IMPORT DATA]\n",
    "ks = pd.read_csv('ks2018.csv')\n",
    "print(\"-\"*100,'\\nData set: {} samples'.format(ks.shape[0]))\n",
    "print(\"-\"*100)\n",
    "\n",
    "# [NULL DATA]\n",
    "print('Null values:')\n",
    "print(ks.isnull().sum())\n",
    "print(\"-\"*100)\n",
    "print('Percentage missing for \"name\" %.4f%%' %((ks['name'].isnull().sum()/ks.shape[0])*100))\n",
    "print('Percentage missing for \"usd pledged\" %.4f%%' %((ks['usd pledged'].isnull().sum()/ks.shape[0])*100))\n",
    "print(\"-\"*100)\n",
    "\n",
    "# [ANALYZE POSSIBLE OUTCOMES]\n",
    "print('Outcomes: ', list(ks.state.unique()))\n",
    "print(\"-\"*100)\n",
    "\n",
    "# [LIVE PROJECTS]\n",
    "live = ks.apply(lambda x: True if x['state'] == 'live' else False , axis=1)\n",
    "print('The amount of live projects is: ', len(live[live == True].index))\n",
    "print('This is %.2f%% of the total projects' %((len(live[live == True].index)/ks.shape[0])*100))\n",
    "print(\"-\"*100)\n",
    "\n",
    "pd.set_option('display.max_columns', None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------------------------------------------------------------------------------------------- \n",
      "New data set: 40000 samples\n",
      "----------------------------------------------------------------------------------------------------\n",
      "                ID                                               name  \\\n",
      "151157  1768168118               The Guardians; An Inevitable Destiny   \n",
      "299626   595769852               UNIQUE ART CREATED FOR YOU, BY ME, G   \n",
      "261486    40001581  uPixy - Secure surfing and custom operating sy...   \n",
      "337917   791338673     Stockton California Community Outreach website   \n",
      "297728   586018162        Addiction Tattoo, Tattooing, Art, Creation.   \n",
      "\n",
      "          category main_category currency   deadline      goal  \\\n",
      "151157     Fiction    Publishing      USD 2016-05-06    8000.0   \n",
      "299626    Painting           Art      CAD 2015-03-22    1700.0   \n",
      "261486    Software    Technology      USD 2015-02-20  100000.0   \n",
      "337917         Web    Journalism      USD 2015-06-20    5000.0   \n",
      "297728  Public Art           Art      USD 2014-12-04    4750.0   \n",
      "\n",
      "                  launched  pledged   state  backers country  usd pledged  \\\n",
      "151157 2016-04-06 01:19:54      8.0  failed        4      US         8.00   \n",
      "299626 2015-02-20 22:50:44    477.0  failed        9      CA       383.55   \n",
      "261486 2015-01-20 22:00:24      1.0  failed        1      US         1.00   \n",
      "337917 2015-05-21 21:26:04      0.0  failed        0      US         0.00   \n",
      "297728 2014-11-04 16:21:56      0.0  failed        0      US         0.00   \n",
      "\n",
      "        usd_pledged_real  usd_goal_real  outcome  \n",
      "151157              8.00        8000.00      0.0  \n",
      "299626            381.33        1359.02      0.0  \n",
      "261486              1.00      100000.00      0.0  \n",
      "337917              0.00        5000.00      0.0  \n",
      "297728              0.00        4750.00      0.0  \n"
     ]
    }
   ],
   "source": [
    "# DATA [CORRECTION, COMPLETION, CONVERSION, DELETION]\n",
    "\n",
    "# remove live projects (0.74% of all data)\n",
    "ks = ks.query('state != \"live\"')\n",
    "\n",
    "# set state to 1 if successful, 0 otherwise, 1 is used for the 'rare class', there are more failed projects thant successful projects\n",
    "ks['outcome'] = (ks['state'] == 'successful').astype(float)\n",
    "\n",
    "# remove projects with null names (0.0011% of all data)\n",
    "ks.drop(ks[ks.name.isnull()].index, axis=0, inplace=True, errors='ignore')\n",
    "\n",
    "# remove outliers: goal over 30 000 000 (unrealistic, jokes)\n",
    "ks.drop(ks[ks.goal > 30000000].index, inplace=True, errors='ignore')\n",
    "\n",
    "# convert launched and deadline columns to datetime objects\n",
    "ks['launched'] = pd.to_datetime(ks['launched'])\n",
    "ks['deadline'] = pd.to_datetime(ks['deadline'])\n",
    "\n",
    "# give unix-time anomalies a new launch date, 30 days before deadline (median, in order to not mess with data)\n",
    "ks.loc[pd.DatetimeIndex(ks['launched']).year < 2000, 'launched'] = ks['deadline'] - pd.to_timedelta(30, unit='d')\n",
    "\n",
    "# reduce size of dataset\n",
    "ks = ks.sample(40000) \n",
    "\n",
    "print(\"-\"*100,'\\nNew data set: {} samples'.format(ks.shape[0]))\n",
    "print(\"-\"*100)\n",
    "\n",
    "print(ks.head(5))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                       outcome\n",
      "ID                    0.003903\n",
      "goal                  0.215746\n",
      "pledged               0.084389\n",
      "backers               0.127531\n",
      "usd pledged           0.067015\n",
      "usd_pledged_real      0.081475\n",
      "usd_goal_real         0.047198\n",
      "outcome               1.000000\n",
      "tlength               0.063052\n",
      "duration              0.120248\n",
      "lyear                 0.081303\n",
      "lmonth                0.008696\n",
      "lday                  0.029425\n",
      "lhour                 0.005000\n",
      "l_is_weekend          0.019147\n",
      "dyear                 0.085134\n",
      "dmonth                0.000993\n",
      "dday                  0.025412\n",
      "project_competition   0.127985\n",
      "category_competition  0.021131\n",
      "success_ratio         0.108298\n",
      "money_spent           0.009380\n",
      "               ID                                               name  \\\n",
      "0      1768168118               The Guardians; An Inevitable Destiny   \n",
      "1      1724235973                                          Roul ECCC   \n",
      "2       343148835             Demonstrations of Modern Transcendence   \n",
      "3      1387821752                                        Blood Queen   \n",
      "4       483248343                NWO FSBO / FAKE BREAST OF CHAMPIONS   \n",
      "...           ...                                                ...   \n",
      "39739    59645040              Free Youth Dance Training Scholarship   \n",
      "39740   177081609                                              Fuego   \n",
      "39741   167214637  Dance 2 Inspire: We are a generation waiting t...   \n",
      "39742   698610682                 Dancing With Props I: Folding Fans   \n",
      "39743  1463801768                               Summer Dance Courses   \n",
      "\n",
      "       category  main_category currency   deadline      goal  \\\n",
      "0            54             12      USD 2016-05-06  8.987197   \n",
      "1            54             12      USD 2013-10-07  9.210340   \n",
      "2            54             12      USD 2012-07-09  8.294050   \n",
      "3            54             12      USD 2016-09-07  6.907755   \n",
      "4            54             12      USD 2014-04-25  8.517193   \n",
      "...         ...            ...      ...        ...       ...   \n",
      "39739       155              3      USD 2017-08-04  8.853665   \n",
      "39740       155              3      USD 2015-04-20  8.517193   \n",
      "39741       155              3      USD 2014-10-24  7.600902   \n",
      "39742       155              3      USD 2017-02-28  5.521461   \n",
      "39743       155              3      GBP 2017-08-15  7.600902   \n",
      "\n",
      "                 launched  pledged       state  backers country  usd pledged  \\\n",
      "0     2016-04-06 01:19:54      8.0      failed        4      US          8.0   \n",
      "1     2013-09-07 05:25:48    661.0      failed       14      US        661.0   \n",
      "2     2012-06-04 06:49:12     95.0      failed        4      US         95.0   \n",
      "3     2016-08-07 05:17:24      0.0    canceled        0      US          0.0   \n",
      "4     2014-03-26 17:53:22    101.0      failed        4      US        101.0   \n",
      "...                   ...      ...         ...      ...     ...          ...   \n",
      "39739 2017-06-24 02:32:43     70.0      failed        2      US          0.0   \n",
      "39740 2015-03-21 20:00:38      0.0      failed        0      US          0.0   \n",
      "39741 2014-09-24 04:44:55      1.0      failed        1      US          1.0   \n",
      "39742 2017-02-07 20:50:35    280.0  successful        9      US         88.0   \n",
      "39743 2017-07-31 20:40:41   2000.0  successful        3      GB          0.0   \n",
      "\n",
      "       usd_pledged_real  usd_goal_real  outcome  tlength  duration  \\\n",
      "0                   8.0         8000.0      0.0       36        30   \n",
      "1                 661.0        10000.0      0.0        9        30   \n",
      "2                  95.0         4000.0      0.0       38        35   \n",
      "3                   0.0         1000.0      0.0       11        31   \n",
      "4                 101.0         5000.0      0.0       35        29   \n",
      "...                 ...            ...      ...      ...       ...   \n",
      "39739              70.0         7000.0      0.0       37        41   \n",
      "39740               0.0         5000.0      0.0        5        29   \n",
      "39741               1.0         2000.0      0.0       60        30   \n",
      "39742             280.0          250.0      1.0       34        20   \n",
      "39743            2574.9         2574.9      1.0       20        14   \n",
      "\n",
      "      category_country  lyear  lmonth  lday  lhour  l_is_weekend  dyear  \\\n",
      "0           Fiction_US   2016       4     2      1             0   2016   \n",
      "1           Fiction_US   2013       9     5      5             1   2013   \n",
      "2           Fiction_US   2012       6     0      6             0   2012   \n",
      "3           Fiction_US   2016       8     6      5             1   2016   \n",
      "4           Fiction_US   2014       3     2     17             0   2014   \n",
      "...                ...    ...     ...   ...    ...           ...    ...   \n",
      "39739     Workshops_US   2017       6     5      2             1   2017   \n",
      "39740     Workshops_US   2015       3     5     20             1   2015   \n",
      "39741     Workshops_US   2014       9     2      4             0   2014   \n",
      "39742     Workshops_US   2017       2     1     20             0   2017   \n",
      "39743     Workshops_GB   2017       7     0     20             0   2017   \n",
      "\n",
      "       dmonth  dday  project_competition  category_competition  success_ratio  \\\n",
      "0           5     4                159.0              9.320833       0.300000   \n",
      "1          10     0                100.0              1.946389       0.400000   \n",
      "2           7     0                 87.0              8.117778       0.533333   \n",
      "3           9     2                107.0             81.839444       0.366667   \n",
      "4           4     4                133.0             71.860556       0.400000   \n",
      "...       ...   ...                  ...                   ...            ...   \n",
      "39739       8     4                100.0           2868.091111       0.333333   \n",
      "39740       4     0                182.0            599.735000       0.266667   \n",
      "39741      10     4                137.0            508.256667       0.200000   \n",
      "39742       2     1                121.0           5146.439167       0.566667   \n",
      "39743       8     1                 81.0            906.132778       0.300000   \n",
      "\n",
      "       money_spent  Art  Comics  Crafts  Dance  Design  Fashion  Film & Video  \\\n",
      "0        633218.00    0       0       0      0       0        0             0   \n",
      "1        263885.63    0       0       0      0       0        0             0   \n",
      "2        177111.79    0       0       0      0       0        0             0   \n",
      "3        151181.12    0       0       0      0       0        0             0   \n",
      "4        315802.71    0       0       0      0       0        0             0   \n",
      "...            ...  ...     ...     ...    ...     ...      ...           ...   \n",
      "39739    164485.00    0       0       0      1       0        0             0   \n",
      "39740    117081.00    0       0       0      1       0        0             0   \n",
      "39741    189562.34    0       0       0      1       0        0             0   \n",
      "39742    123217.87    0       0       0      1       0        0             0   \n",
      "39743   1204661.54    0       0       0      1       0        0             0   \n",
      "\n",
      "       Food  Games  Journalism  Music  Photography  Publishing  Technology  \\\n",
      "0         0      0           0      0            0           1           0   \n",
      "1         0      0           0      0            0           1           0   \n",
      "2         0      0           0      0            0           1           0   \n",
      "3         0      0           0      0            0           1           0   \n",
      "4         0      0           0      0            0           1           0   \n",
      "...     ...    ...         ...    ...          ...         ...         ...   \n",
      "39739     0      0           0      0            0           0           0   \n",
      "39740     0      0           0      0            0           0           0   \n",
      "39741     0      0           0      0            0           0           0   \n",
      "39742     0      0           0      0            0           0           0   \n",
      "39743     0      0           0      0            0           0           0   \n",
      "\n",
      "       Theater  mean_category_goal  category_count  mean_main_category_goal  \\\n",
      "0            0            8.033182           12012                 8.326142   \n",
      "1            0            8.033182           12012                 8.326142   \n",
      "2            0            8.033182           12012                 8.326142   \n",
      "3            0            8.033182           12012                 8.326142   \n",
      "4            0            8.033182           12012                 8.326142   \n",
      "...        ...                 ...             ...                      ...   \n",
      "39739        0            8.213370              48                 8.202437   \n",
      "39740        0            8.213370              48                 8.202437   \n",
      "39741        0            8.213370              48                 8.202437   \n",
      "39742        0            8.213370              48                 8.202437   \n",
      "39743        0            8.213370              48                 8.202437   \n",
      "\n",
      "       main_category_count  diff_mean_category_goal  \n",
      "0                   289397                -0.661055  \n",
      "1                   289397                -0.884199  \n",
      "2                   289397                 0.032092  \n",
      "3                   289397                 1.418386  \n",
      "4                   289397                -0.191051  \n",
      "...                    ...                      ...  \n",
      "39739                27176                -0.651228  \n",
      "39740                27176                -0.314756  \n",
      "39741                27176                 0.601535  \n",
      "39742                27176                 2.680976  \n",
      "39743                27176                 0.601535  \n",
      "\n",
      "[39744 rows x 51 columns]\n"
     ]
    }
   ],
   "source": [
    "# FEATURE [CREATION, ENGINEERING]\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "# log transformation on goal column\n",
    "ks['goal'] = np.log(ks.goal)\n",
    "\n",
    "# create titlelength feature (length of the project name)\n",
    "ks['tlength'] = ks['name'].str.len()\n",
    "\n",
    "# create duration feature (campaign duration in days, rounded up)\n",
    "ks['duration'] = ((ks['deadline'] - ks['launched']) / np.timedelta64(1, 'D')).round(0).astype(int)\n",
    "\n",
    "# remove outliers: duration over 85\n",
    "ks.drop(ks[ks.duration > 85].index, inplace=True, errors='ignore')\n",
    "\n",
    "# create category_country feature (combination of category + country)\n",
    "ks['category_country'] = ks['category'] + \"_\" + ks['country']\n",
    "\n",
    "# create launch features (year, month [1,12], day of week [0,6], hour and is_weekend)\n",
    "ks['lyear'] = pd.DatetimeIndex(ks['launched']).year\n",
    "ks['lmonth'] = pd.DatetimeIndex(ks['launched']).month\n",
    "ks['lday'] = pd.DatetimeIndex(ks['launched']).dayofweek\n",
    "ks['lhour'] = pd.DatetimeIndex(ks['launched']).hour\n",
    "ks[\"l_is_weekend\"] = ks[\"lday\"].apply(lambda x: 1 if x > 4 else 0)\n",
    "\n",
    "# create deadline features (year, month [1,12] and day of week [0,6])\n",
    "ks['dyear'] = pd.DatetimeIndex(ks['deadline']).year\n",
    "ks['dmonth'] = pd.DatetimeIndex(ks['deadline']).month\n",
    "ks['dday'] = pd.DatetimeIndex(ks['deadline']).dayofweek \n",
    "\n",
    "# create project_competition feature (number of projects launched in past week)\n",
    "launches = pd.Series(ks.index, index=ks.launched, name=\"project_competition\").sort_index()\n",
    "project_competition = launches.rolling('7d').count() - 1 \n",
    "project_competition.index = launches.values\n",
    "ks['project_competition'] = project_competition.reindex(ks.index)\n",
    "\n",
    "# create category_competition feature (time since last project in same category was launched)\n",
    "def time_since_last_project(series): return series.diff().dt.total_seconds() / 3600.\n",
    "df = ks[['category', 'launched']].sort_values('launched')\n",
    "timedeltas = df.groupby('category').transform(time_since_last_project)\n",
    "ks['category_competition'] = timedeltas.fillna(timedeltas.median()).reindex(ks.index)\n",
    "\n",
    "# create success ratio feature (kickstarter success ratio during previous month)\n",
    "df = ks[['outcome', 'deadline']].sort_values('deadline')\n",
    "df['outcome'] = df['outcome'].astype(float)\n",
    "df['sum_outcomes'] = df['outcome'].rolling(window=30).sum() - df['outcome'] \n",
    "df['count_outcomes'] = df['outcome'].rolling(window=30).count()\n",
    "df['success_ratio'] = df['sum_outcomes']/df['count_outcomes']\n",
    "ks['success_ratio'] = df['success_ratio'].fillna(df['success_ratio'].median()).reindex(ks.index)\n",
    "\n",
    "# create money spent feature (how much money was already spent last month)\n",
    "df = ks[['pledged', 'deadline']].sort_values('deadline')\n",
    "df['sum_pledged'] = df['pledged'].rolling(window=30).sum() - df['pledged'] \n",
    "ks['money_spent'] = df['sum_pledged'].fillna(df['sum_pledged'].median()).reindex(ks.index)\n",
    "\n",
    "print(ks.corr().abs()[['outcome']])\n",
    "\n",
    "# transform category in multiple colums with one hot encoding, so it can be used to compute category related features\n",
    "ks = pd.concat([ks, pd.get_dummies(ks[\"main_category\"])], axis = 1)\n",
    "le = LabelEncoder()\n",
    "for c in [\"category\", \"main_category\"]:\n",
    "    ks[c] = le.fit_transform(ks[c])\n",
    "\n",
    "# create category related features\n",
    "t2 = ks.groupby(\"main_category\").agg({\"goal\" : \"mean\", \"category\" : \"sum\"})\n",
    "t1 = ks.groupby(\"category\").agg({\"goal\" : \"mean\", \"main_category\" : \"sum\"})\n",
    "t2 = t2.reset_index().rename(columns={\"goal\" : \"mean_main_category_goal\", \"category\" : \"main_category_count\"})\n",
    "t1 = t1.reset_index().rename(columns={\"goal\" : \"mean_category_goal\", \"main_category\" : \"category_count\"})\n",
    "ks = ks.merge(t1, on = \"category\")\n",
    "ks = ks.merge(t2, on = \"main_category\")\n",
    "\n",
    "ks[\"diff_mean_category_goal\"] = ks[\"mean_category_goal\"] - ks[\"goal\"]\n",
    "ks[\"diff_mean_category_goal\"] = ks[\"mean_main_category_goal\"] - ks[\"goal\"]\n",
    "\n",
    "# create money spent feature\n",
    "#def mony_spend_last_month():\n",
    "    \n",
    "#df = ks[['category', 'launched', 'deadline', 'usd pledged']].sort_values('launched')\n",
    "#moneydeltas = df.groupby('category').transform(mony_spend_last_month)\n",
    "#moneydeltas = moneydeltas.fillna(moneydeltas.median()).reindex(ks.index)\n",
    "\n",
    "#ks['category_money'] = moneydeltas\n",
    "#print(df)\n",
    "\n",
    "# print result\n",
    "print(ks)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 2160x360 with 3 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "sns.countplot(x = 'outcome', data = ks, palette = 'Set3')\n",
    "\n",
    "\n",
    "# FIND OUTLIERS\n",
    "fig, axs = plt.subplots(ncols=3, figsize=(30,5))\n",
    "\n",
    "# goal, kickstarter maximum is 100.000\n",
    "axs[0].set_title(\"goal\")\n",
    "ks['goal'].plot(kind='hist', bins=20, color='darkseagreen', edgecolor='black', log=True, range=[-5,3], ax=axs[0])\n",
    "\n",
    "# tlength\n",
    "axs[1].set_title(\"tlength\")\n",
    "ks['tlength'].plot(kind='hist', bins=20, color='darkseagreen', edgecolor='black', log=True, range=[0,100], ax=axs[1])\n",
    "\n",
    "# duration\n",
    "axs[2].set_title(\"duration\")\n",
    "ks['duration'].plot(kind='hist', bins=20, color='darkseagreen', edgecolor='black', log=True, range=[0,100], ax=axs[2])\n",
    "\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   outcome  category  main_category      goal  duration  tlength  lyear  \\\n",
      "0      0.0        54             12  8.987197        30       36   2016   \n",
      "1      0.0        54             12  9.210340        30        9   2013   \n",
      "2      0.0        54             12  8.294050        35       38   2012   \n",
      "3      0.0        54             12  6.907755        31       11   2016   \n",
      "4      0.0        54             12  8.517193        29       35   2014   \n",
      "\n",
      "   lmonth  lday  l_is_weekend  lhour  dyear  dmonth  dday  \\\n",
      "0       4     2             0      1   2016       5     4   \n",
      "1       9     5             1      5   2013      10     0   \n",
      "2       6     0             0      6   2012       7     0   \n",
      "3       8     6             1      5   2016       9     2   \n",
      "4       3     2             0     17   2014       4     4   \n",
      "\n",
      "   category_competition  project_competition  mean_category_goal  \\\n",
      "0              9.320833                159.0            8.033182   \n",
      "1              1.946389                100.0            8.033182   \n",
      "2              8.117778                 87.0            8.033182   \n",
      "3             81.839444                107.0            8.033182   \n",
      "4             71.860556                133.0            8.033182   \n",
      "\n",
      "   category_count  mean_main_category_goal  main_category_count  \\\n",
      "0           12012                 8.326142               289397   \n",
      "1           12012                 8.326142               289397   \n",
      "2           12012                 8.326142               289397   \n",
      "3           12012                 8.326142               289397   \n",
      "4           12012                 8.326142               289397   \n",
      "\n",
      "   diff_mean_category_goal  category_competition  currency   country  \\\n",
      "0                -0.661055              9.320833  0.374733  0.378402   \n",
      "1                -0.884199              1.946389  0.374733  0.378402   \n",
      "2                 0.032092              8.117778  0.374733  0.378402   \n",
      "3                 1.418386             81.839444  0.374733  0.378402   \n",
      "4                -0.191051             71.860556  0.374733  0.378402   \n",
      "\n",
      "   category_country  \n",
      "0          0.254118  \n",
      "1          0.254118  \n",
      "2          0.254118  \n",
      "3          0.254118  \n",
      "4          0.254118  \n"
     ]
    }
   ],
   "source": [
    "# CATEGORICAL ENCODING (one-hot encoding, label encoding, count encoding, target encoding, catboost encoding)\n",
    "\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "import category_encoders as ce\n",
    "\n",
    "# categorical features to be encoded\n",
    "# features = ['category', 'currency', 'country', 'category_country']\n",
    "features = ['currency', 'country', 'category_country']\n",
    "\n",
    "# encoders\n",
    "l_encoder = LabelEncoder() # label encoding, encode target labels with value between 0 and n_classes-1.\n",
    "c_encoder = ce.CountEncoder() # count encoding, replaces each categorical value with the number of times it appears in the dataset\n",
    "t_encoder = ce.TargetEncoder(cols=features) # target encoding, replaces a categorical value with the average value of the target for that value of the feature\n",
    "cb_encoder = ce.CatBoostEncoder(cols=features) # catboost encoding, for each row, the target probability is calculated only from the rows before it\n",
    "\n",
    "# encoded features\n",
    "l_encoded = ks[features].apply(l_encoder.fit_transform)\n",
    "c_encoded = c_encoder.fit_transform(ks[features])\n",
    "t_encoded = t_encoder.fit_transform(ks[features], ks['outcome'])\n",
    "cb_encoded = cb_encoder.fit_transform(ks[features], ks['outcome'])\n",
    "\n",
    "# create data set, drop colums of features that are not useful\n",
    "ks.drop('currency', axis=1, inplace=True)\n",
    "ks.drop('country', axis=1, inplace=True)\n",
    "ks.drop('category_country', axis=1, inplace=True)\n",
    "ks.drop('name', axis=1, inplace=True)\n",
    "ks.drop('launched', axis=1, inplace=True)\n",
    "ks.drop('deadline', axis=1, inplace=True)\n",
    "ks.drop('usd pledged', axis=1, inplace=True)\n",
    "ks.drop('state', axis=1, inplace=True)\n",
    "#data = ks[['outcome', 'tlength', 'goal', 'duration', 'lyear', 'lmonth', 'lday', 'lhour', 'dyear', 'dmonth', 'dday', 'project_competition', 'category_competition']].join(t_encoded)\n",
    "data = ks[['outcome', 'category', 'main_category', 'goal', 'duration', 'tlength', 'lyear', 'lmonth', 'lday', 'l_is_weekend', 'lhour', 'dyear', 'dmonth', 'dday', 'category_competition', 'project_competition', 'mean_category_goal', 'category_count', 'mean_main_category_goal', 'main_category_count', 'diff_mean_category_goal', 'category_competition']].join(t_encoded)\n",
    "#data = ks.join(t_encoded)\n",
    "\n",
    "# print result\n",
    "print(data.head(5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    index                  Feature  Feature Importance\n",
      "0      23         category_country            0.453112\n",
      "1       2                     goal            0.116805\n",
      "2      19  diff_mean_category_goal            0.078436\n",
      "3       3                 duration            0.064790\n",
      "4      14      project_competition            0.061494\n",
      "5       9                    lhour            0.035411\n",
      "6       4                  tlength            0.034193\n",
      "7      20     category_competition            0.022383\n",
      "8      13     category_competition            0.018449\n",
      "9       0                 category            0.014557\n",
      "10     11                   dmonth            0.012080\n",
      "11     15       mean_category_goal            0.010988\n",
      "12      7                     lday            0.010309\n",
      "13     16           category_count            0.009266\n",
      "14     10                    dyear            0.008152\n",
      "15      5                    lyear            0.007473\n",
      "16     21                 currency            0.006706\n",
      "17     18      main_category_count            0.006500\n",
      "18     22                  country            0.006209\n",
      "19     12                     dday            0.006079\n",
      "20      1            main_category            0.005884\n",
      "21      6                   lmonth            0.005686\n",
      "22     17  mean_main_category_goal            0.003866\n",
      "23      8             l_is_weekend            0.001173\n"
     ]
    }
   ],
   "source": [
    "# FEATURE SELECTION\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "X = data.drop('outcome', axis = 1).values\n",
    "y = data['outcome']\n",
    "dt = DecisionTreeClassifier(random_state=15, criterion = 'entropy', max_depth = 10)\n",
    "dt.fit(X,y)\n",
    "fi_col = []\n",
    "fi = []\n",
    "for i,column in enumerate(data.drop('outcome', axis = 1)):\n",
    "    fi_col.append(column)\n",
    "    fi.append(dt.feature_importances_[i])\n",
    "fi_col\n",
    "fi\n",
    "fi_df = zip(fi_col, fi)\n",
    "fi_df = pd.DataFrame(fi_df, columns = ['Feature','Feature Importance'])\n",
    "fi_df = fi_df.sort_values('Feature Importance', ascending = False).reset_index()\n",
    "\n",
    "# Creating columns to keep\n",
    "columns_to_keep = fi_df['Feature'][0:10]\n",
    "\n",
    "print(fi_df)\n",
    "\n",
    "# feature selection\n",
    "#data = data[['outcome', 'category', 'main_category', 'category_country', 'goal', 'duration', 'tlength', 'lyear', 'lmonth', 'lday', 'l_is_weekend', 'lhour', 'dyear', 'dmonth', 'dday', 'category_competition', 'project_competition', 'mean_category_goal', 'category_count', 'mean_main_category_goal', 'main_category_count', 'diff_mean_category_goal', 'category_competition']]\n",
    "\n",
    "# correlations\n",
    "#data.corr().abs()[['outcome']]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------\n",
      "[60%] x_train:\t 23846\n",
      "[20%] x_test:\t 15898\n",
      "-----------------------------------\n"
     ]
    }
   ],
   "source": [
    "# SCALE AND SPLIT DATA\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "# get predictors: goal, duration, project_competition, category, category_country\n",
    "x_unscaled = data[['goal', 'duration', 'project_competition', 'category', 'category_country']]\n",
    "\n",
    "# get outcome\n",
    "y = data['outcome']\n",
    "\n",
    "# feature scaling/normalizing\n",
    "scaler = StandardScaler()\n",
    "x = pd.DataFrame(scaler.fit_transform(x_unscaled), columns=list(x_unscaled.columns))\n",
    "\n",
    "\n",
    "# split data into training, testing and validation set (60%, 20%, 20%)\n",
    "# data -> training + testing\n",
    "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.4, random_state=42)\n",
    "\n",
    "# training -> training + cross validation\n",
    "#x_train, x_valid, y_train, y_valid = train_test_split(x_train, y_train, test_size=0.25, random_state=42)\n",
    "\n",
    "print(\"-\"*35)\n",
    "print(\"[60%] x_train:\\t\", x_train.shape[0])\n",
    "#print(\"[20%] x_valid:\\t\", x_valid.shape[0])\n",
    "print(\"[20%] x_test:\\t\", x_test.shape[0])\n",
    "print(\"-\"*35)\n",
    "\n",
    "# check if data is nicely spread\n",
    "# https://imgur.com/a/cCCjKhj\n",
    "# in the image above you see that the projects with outcome 1 are evenly spread among the sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.698 (0.006)\n",
      "------------------------------------------------------------\n",
      "Logistic Regression Model Scores\n",
      "[TEST]\t 69.36%\n",
      "------------------------------------------------------------\n",
      "Classification Report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.72      0.85      0.78     10187\n",
      "         1.0       0.61      0.41      0.49      5711\n",
      "\n",
      "    accuracy                           0.69     15898\n",
      "   macro avg       0.66      0.63      0.64     15898\n",
      "weighted avg       0.68      0.69      0.68     15898\n",
      "\n",
      "------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "# LOGISTIC REGRESSION \n",
    "from numpy import mean, std\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import cross_val_score, cross_val_predict\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.model_selection import learning_curve, KFold\n",
    "from sklearn import metrics\n",
    "\n",
    "# prepare the cross-validation procedure\n",
    "cv = KFold(n_splits=10, random_state=1, shuffle=True)\n",
    "\n",
    "# create model\n",
    "model = LogisticRegression()\n",
    "\n",
    "# evaluate model\n",
    "scores = cross_val_score(model, x_train, y_train, scoring='accuracy', cv=cv, n_jobs=-1)\n",
    "\n",
    "# report performance\n",
    "print('Accuracy: %.3f (%.3f)' % (mean(scores), std(scores)))\n",
    "\n",
    "\n",
    "# create model\n",
    "#model = LogisticRegression(C=0.01)\n",
    "\n",
    "# fit model on training data set\n",
    "model.fit(x_train, y_train)\n",
    "\n",
    "# test model on cross validation data set\n",
    "#y_pred_valid = model.predict(x_valid) \n",
    "\n",
    "\n",
    "# model score: score(test samples, true labels for x)\n",
    "print(\"-\"*60)\n",
    "print(\"Logistic Regression Model Scores\")\n",
    "#print('[TRAIN]\\t %.2f%%' %(round(model.score(x_train, y_train),5)*100))\n",
    "#print('[VALID]\\t %.2f%%' %(round(model.score(x_valid, y_valid),5)*100))\n",
    "print('[TEST]\\t %.2f%%' %(round(model.score(x_test, y_test),5)*100))\n",
    "y_pred_test = model.predict(x_test) \n",
    "print(\"-\"*60)\n",
    "\n",
    "# classification report: classification_report(y_true, y_pred)\n",
    "print(\"Classification Report\")\n",
    "print(classification_report(y_test, y_pred_test))\n",
    "print(\"-\"*60)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CONFUSION MATRIX LOGISTIC REGRESSION\n",
    "import itertools\n",
    "\n",
    "def plot_confusion_matrix(cm, classes, normalize=False, title=\"Confusion Matrix\", cmap=plt.cm.YlGnBu):\n",
    "    if normalize: cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
    "\n",
    "    plt.imshow(cm, interpolation='nearest', cmap=cmap)\n",
    "    plt.title(title)\n",
    "    plt.colorbar()\n",
    "    tick_marks = np.arange(len(classes))\n",
    "    plt.xticks(tick_marks, classes, rotation=45)\n",
    "    plt.yticks(tick_marks, classes)\n",
    "\n",
    "    fmt = '.2f' if normalize else 'd'\n",
    "    thresh = cm.max() / 2.\n",
    "    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n",
    "        plt.text(j, i, format(cm[i, j], fmt),\n",
    "            horizontalalignment=\"center\",\n",
    "            color=\"white\" if cm[i, j] > thresh else \"black\",\n",
    "            size=\"20\")\n",
    "           \n",
    "    plt.tight_layout()\n",
    "    plt.ylabel('True label')\n",
    "    plt.xlabel('Predicted label')\n",
    "\n",
    "\n",
    "# confusion matrix: confusion_matrix(y_true, y_pred)\n",
    "cnf_matrix = metrics.confusion_matrix(y_valid, y_pred_valid)\n",
    "np.set_printoptions(precision=2)\n",
    "class_names = ['Successful', 'Failed']\n",
    "\n",
    "plt.figure()\n",
    "plot_confusion_matrix(cnf_matrix, classes=class_names, title='Confusion Matrix')\n",
    "\n",
    "plt.figure()\n",
    "plot_confusion_matrix(cnf_matrix, classes=class_names, normalize=True, title='Normalized Confusion Matrix')\n",
    "\n",
    "# evaluation of confusion matrix\n",
    "print(\"-\"*60)\n",
    "print('[ACCURACY]\\t %.2f%%' %(metrics.accuracy_score(y_valid, y_pred_valid)*100))\n",
    "print('[PRECISION]\\t %.2f%%' %(metrics.precision_score(y_valid, y_pred_valid)*100))\n",
    "print('[RECALL]\\t %.2f%%' %(metrics.recall_score(y_valid, y_pred_valid)*100))\n",
    "print(\"-\"*60)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_proba_train = model.predict_proba(x_train) # training\n",
    "y_pred_proba_test = model.predict_proba(x_test) # testing\n",
    "y_pred_proba_valid = model.predict_proba(x_valid) # validation\n",
    "\n",
    "# Running Log loss on training\n",
    "print(\"The Log Loss on Training is: \", metrics.log_loss(y_train, y_pred_proba_train))\n",
    "print(\"The Log Loss on Testing Dataset is: \", metrics.log_loss(y_test, y_pred_proba_test))\n",
    "\n",
    "# RECEIVER OPERATING CHARACTERISTIC (ROC) CURVE: roc_curve(y_true, y_score)\n",
    "print(\"ROC Curve\")\n",
    "y_pred_proba = model.predict_proba(x_test)[::,1]\n",
    "fpr, tpr, _ = metrics.roc_curve(y_test, y_pred_proba)\n",
    "auc = metrics.roc_auc_score(y_test, y_pred_proba)\n",
    "plt.plot(fpr,tpr,label=\"data 1, auc=\"+str(auc))\n",
    "plt.legend(loc=4)\n",
    "plt.show()\n",
    "print(f\"Test AUC score: {auc}\")\n",
    "print(\"-\"*60)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# learning curve for when using whole dataset\n",
    "# train_sizes, train_scores, validation_scores = learning_curve(estimator = LogisticRegression(), X=x_train, y=y_train, train_sizes = [500, 1000, 1100, 1200, 1300, 1400, 1500, 1600, 1700, 1800, 1900, 2000, 3000, 4000, 5000, 6000, 7000, 8000, 9000, 1000, 15000, 20000, 25000, 25000, 30000, 35000, 40000, 45000, 50000], cv = 5)\n",
    "# learning curve for when using part of dataset\n",
    "train_sizes, train_scores, validation_scores = learning_curve(estimator = LogisticRegression(), X=x_train, y=y_train, train_sizes = [0.01, 0.02, 0.05, 0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9, 1.0], cv = 5)\n",
    "\n",
    "train_scores_mean = train_scores.mean(axis = 1)\n",
    "validation_scores_mean = validation_scores.mean(axis = 1)\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.style.use('seaborn')\n",
    "plt.plot(train_sizes, train_scores_mean, label = 'Training error')\n",
    "plt.plot(train_sizes, validation_scores_mean, label = 'Validation error')\n",
    "plt.ylabel('MSE', fontsize = 14)\n",
    "plt.xlabel('Training set size', fontsize = 14)\n",
    "plt.title('Learning curves for a logistic regression model', fontsize = 18, y = 1.03)\n",
    "plt.legend()\n",
    "#plt.ylim(0.68,0.703)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Optimal C/lambda value\n",
    "from sklearn.linear_model import LogisticRegressionCV\n",
    "from sklearn.model_selection import KFold\n",
    "kf = KFold(n_splits=3, random_state=0, shuffle=True)\n",
    "\n",
    "C_List = np.geomspace(1e-5, 1e5, num=20)\n",
    "\n",
    "# Logistic Reg CV\n",
    "Log_reg3 = LogisticRegressionCV(random_state=15, Cs = C_List, solver ='lbfgs')\n",
    "Log_reg3.fit(x_train, y_train)\n",
    "print(\"The CA is:\", Log_reg3.score(x_test, y_test))\n",
    "pred_proba_t = Log_reg3.predict_proba(x_test)\n",
    "log_loss3 = metrics.log_loss(y_test, pred_proba_t)\n",
    "print(\"The Logistic Loss is: \", log_loss3)\n",
    "\n",
    "print(\"The optimal C parameter is: \", Log_reg3.C_)\n",
    "\n",
    "\n",
    "#C_List = np.geomspace(1e-5, 1e5, num=20)\n",
    "CA = []\n",
    "Logarithmic_Loss = []\n",
    "\n",
    "for c in C_List:\n",
    "    log_reg2 = LogisticRegression(random_state=10, solver = 'lbfgs', C=c)\n",
    "    log_reg2.fit(x_train, y_train)\n",
    "    score = log_reg2.score(x_test, y_test)\n",
    "    CA.append(score)\n",
    "    print(\"The CA of C parameter {} is {}:\".format(c, score))\n",
    "    pred_proba_t = log_reg2.predict_proba(x_test)\n",
    "    log_loss2 = metrics.log_loss(y_test, pred_proba_t)\n",
    "    Logarithmic_Loss.append(log_loss2)\n",
    "    print(\"The Logg Loss of C parameter {} is {}:\".format(c, log_loss2))\n",
    "    print(\"\")\n",
    "    \n",
    "    y_pred = log_reg2.predict(x_train)\n",
    "    cm = metrics.confusion_matrix(y_train, y_pred)\n",
    "    #cm_norm = cm / cm.sum(axis=1).reshape(-1,1)\n",
    "    plot_confusion_matrix(cm, normalize=True, classes = model.classes_, title='Confusion matrix', cmap=plt.cm.YlGnBu)\n",
    "    plt.show()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# DON'T EXECUTE! crashte bij mij idk waarom\n",
    "# LightGBM\n",
    "# Tree-based model that typically provides the best performance, even compared to XGBoost. It's also relatively fast to train.\n",
    "\n",
    "import lightgbm as lgb\n",
    "from sklearn import metrics\n",
    "\n",
    "feature_cols = data.columns.drop('outcome')\n",
    "\n",
    "dtrain = lgb.Dataset(data[feature_cols], label=data['outcome'])\n",
    "dvalid = lgb.Dataset(data[feature_cols], label=data['outcome'])\n",
    "\n",
    "param = {'num_leaves': 64, 'objective': 'binary'}\n",
    "param['metric'] = 'auc'\n",
    "num_round = 1000\n",
    "bst = lgb.train(param, dtrain, num_round, valid_sets=[dvalid], early_stopping_rounds=10, verbose_eval=False)\n",
    "\n",
    "ypred = bst.predict(test[feature_cols])\n",
    "score = metrics.roc_auc_score(test['outcome'], ypred)\n",
    "\n",
    "# evaluation\n",
    "print(\"-\"*60)\n",
    "print('Aread Under Curve (AUC): %.2f%%' %(metrics.roc_auc_score(test['outcome'], ypred)*100))\n",
    "print(\"-\"*60)\n",
    "\n",
    "#76.06 (catboost)\n",
    "#76.83 (target)\n",
    "#76.34 (count)\n",
    "#76.33 (label)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# NAIVE BAYES ALGORITHM\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn import metrics\n",
    "\n",
    "# instantiate logistic regression model\n",
    "model = GaussianNB()\n",
    "\n",
    "# fit the model with the data\n",
    "model.fit(x_train,y_train)\n",
    "\n",
    "# make predictions\n",
    "predict_test = model.predict(x_test)\n",
    "\n",
    "# evaluation\n",
    "print(\"-\"*60)\n",
    "print('Accuracy: %.2f%%' %(metrics.accuracy_score(y_test, predict_test)*100))\n",
    "print('Precision: %.2f%%' %(metrics.precision_score(y_test, predict_test)*100))\n",
    "print('Recall: %.2f%%' %(metrics.recall_score(y_test, predict_test)*100))\n",
    "print(\"-\"*60)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# NEURAL NETWORK\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "\n",
    "model = keras.Sequential()\n",
    "\n",
    "model.add(layers.Dense(2, activation=\"relu\"))\n",
    "model.add(layers.Dense(3, activation=\"relu\"))\n",
    "model.add(layers.Dense(4))\n",
    "\n",
    "#model.compile(optimizer=\"adam\", loss='binary_crossentropy', metrics=['accuracy'])\n",
    "#model.fit(x_train, y_train, batch_size=32, epochs=50)\n",
    "\n",
    "#model.summary()\n",
    "\n",
    "#y_pred = model.predict_classes(x_test)\n",
    "#print(metrics.accuracy_score(y_test, y_pred))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SUPORRT VECTOR MACHINES\n",
    "from sklearn import svm\n",
    "from sklearn import metrics\n",
    "\n",
    "# Split dataset in train, validate, test sets\n",
    "# x_train, x_valid, x_test, y_train, y_valid, y_test\n",
    "\n",
    "# Create a svm Classifier\n",
    "clf = svm.SVC(kernel='rbf') # Linear Kernel, or radial basis function?\n",
    "\n",
    "# Train the model using the training sets\n",
    "clf.fit(x_train, y_train)\n",
    "\n",
    "# test model on cross validation data set\n",
    "y_pred_valid_SVM = clf.predict(x_valid)\n",
    "\n",
    "# model score: score(test samples, true labels for x)\n",
    "print(\"-\"*60)\n",
    "print(\"Support Vector Machines Model Scores\")\n",
    "print('[TRAIN]\\t %.2f%%' %(round(clf.score(x_train, y_train),5)*100))\n",
    "print('[VALID]\\t %.2f%%' %(round(clf.score(x_valid, y_valid),5)*100))\n",
    "print('[TEST]\\t %.2f%%' %(round(clf.score(x_test, y_test),5)*100))\n",
    "print(\"-\"*60)\n",
    "\n",
    "# classification report: classification_report(y_true, y_pred)\n",
    "print(\"Classification Report\")\n",
    "print(classification_report(y_valid, y_pred_valid_SVM))\n",
    "print(\"-\"*60)\n",
    "\n",
    "# evaluationg the model\n",
    "#print(\"Accuracy:\",metrics.accuracy_score(y_test, y_pred_valid))\n",
    "#print(\"Precision:\",metrics.precision_score(y_test, y_pred_valid))\n",
    "#print(\"Recall:\",metrics.recall_score(y_test, y_pred_valid))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CONFUSION MATRIX SVM\n",
    "\n",
    "def plot_confusion_matrix(cm, classes, normalize=False, title=\"Confusion Matrix\", cmap=plt.cm.YlGnBu):\n",
    "    if normalize: cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
    "\n",
    "    plt.imshow(cm, interpolation='nearest', cmap=cmap)\n",
    "    plt.title(title)\n",
    "    plt.colorbar()\n",
    "    tick_marks = np.arange(len(classes))\n",
    "    plt.xticks(tick_marks, classes, rotation=45)\n",
    "    plt.yticks(tick_marks, classes)\n",
    "\n",
    "    fmt = '.2f' if normalize else 'd'\n",
    "    thresh = cm.max() / 2.\n",
    "    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n",
    "        plt.text(j, i, format(cm[i, j], fmt),\n",
    "            horizontalalignment=\"center\",\n",
    "            color=\"white\" if cm[i, j] > thresh else \"black\",\n",
    "            size=\"20\")\n",
    "           \n",
    "    plt.tight_layout()\n",
    "    plt.ylabel('True label')\n",
    "    plt.xlabel('Predicted label')\n",
    "\n",
    "\n",
    "# confusion matrix: confusion_matrix(y_true, y_pred)\n",
    "cnf_matrix = metrics.confusion_matrix(y_valid, y_pred_valid)\n",
    "np.set_printoptions(precision=2)\n",
    "class_names = ['Successful', 'Failed']\n",
    "\n",
    "plt.figure()\n",
    "plot_confusion_matrix(cnf_matrix, classes=class_names, title='Confusion Matrix')\n",
    "\n",
    "plt.figure()\n",
    "plot_confusion_matrix(cnf_matrix, classes=class_names, normalize=True, title='Normalized Confusion Matrix')\n",
    "\n",
    "# evaluation of confusion matrix\n",
    "print(\"-\"*60)\n",
    "print('[ACCURACY]\\t %.2f%%' %(metrics.accuracy_score(y_valid, y_pred_valid_SVM)*100))\n",
    "print('[PRECISION]\\t %.2f%%' %(metrics.precision_score(y_valid, y_pred_valid_SVM)*100))\n",
    "print('[RECALL]\\t %.2f%%' %(metrics.recall_score(y_valid, y_pred_valid_SVM)*100))\n",
    "print(\"-\"*60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
